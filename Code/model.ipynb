{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusfilvi@GU.GU.SE/.conda/envs/AICS/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, DistilBertModel, VisualBertModel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast, os, cv2\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, classification_report\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "detector = torchvision.models.resnet50(pretrained=True)\n",
    "detector = torch.nn.Sequential(*list(detector.children())[:-1])\n",
    "detector.eval()\n",
    "\n",
    "batch_size = 4\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(image_list):\n",
    "    image_list = torch.stack(image_list)\n",
    "    vis_embeddings = detector(image_list)\n",
    "    return vis_embeddings\n",
    "\n",
    "def map_values(ratings, tags):\n",
    "    for i, tag in enumerate(tags):\n",
    "        if tag == 'concrete':\n",
    "            ratings[i] = 0\n",
    "        elif tag == 'middle':\n",
    "            ratings[i] = 1\n",
    "        else:\n",
    "            ratings[i] = 2\n",
    "    return ratings\n",
    "\n",
    "class Multimodal_Dataset(Dataset):\n",
    "    def __init__(self, words_file, image_file, tokenizer, regression=False):\n",
    "        self.words_file = words_file\n",
    "        self.images = image_file\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.data = pd.read_csv(words_file)\n",
    "        self.words = self.data['word'].to_list()\n",
    "        self.encodings = self.tokenizer([word for word in self.words], add_special_tokens=True, padding='max_length', max_length=12,return_tensors='pt')\n",
    "\n",
    "        self.photos = self.data['photos'].apply(ast.literal_eval)\n",
    "        self.labels = self.data['tag'].to_list()\n",
    "        if regression == True:\n",
    "            self.ratings = self.data['rating'].to_list()\n",
    "        else:\n",
    "            ratings = self.data['rating'].to_list()\n",
    "            self.ratings = map_values(ratings, self.labels)\n",
    "\n",
    "        transform_list = [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "        self.transform = transforms.Compose(transform_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images = self.photos[idx]\n",
    "        imgs = []\n",
    "        for image in images:\n",
    "          img_path = os.path.join('images/', image)\n",
    "          img = Image.open(img_path)\n",
    "          img = img.convert('RGB')\n",
    "          img = self.transform(img)\n",
    "          \n",
    "          imgs.append(img)\n",
    "\n",
    "        #padding list of images\n",
    "        while len(imgs) < 12:\n",
    "            imgs.append(torch.zeros_like(imgs[0]))\n",
    "\n",
    "        embeddings = get_features(imgs)\n",
    "\n",
    "        item = {'word': self.words[idx], 'input_ids': self.encodings['input_ids'][idx], 'attn_mask': self.encodings['attention_mask'][idx], 'token_type_ids': self.encodings['token_type_ids'], 'visual_embeddings': embeddings, 'rating': self.ratings[idx],'label': self.labels[idx]}\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 2048, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Multimodal_Dataset('merged_data.csv', 'images', tokenizer=tokenizer)\n",
    "data[5]['visual_embeddings'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Textual BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEXTUAL_BERT(nn.Module):\n",
    "  def __init__(self, num_of_labels):\n",
    "      super(TEXTUAL_BERT, self).__init__()\n",
    "      self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "      self.classifier = nn.Linear(self.bert.config.hidden_size, num_of_labels)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "      outputs = self.bert(input_ids, attention_mask)\n",
    "      predictions = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
    "\n",
    "      return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [01:52<00:00,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 1.115250007311503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = TEXTUAL_BERT(3).to(device)\n",
    "\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "predictions = []\n",
    "gold_labels = []\n",
    "misclassifications = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm.tqdm(dataloader):\n",
    "\n",
    "        #embed(); raise\n",
    "        input_ids = batch['input_ids'].long().to(device)\n",
    "        attn_masks = batch['attn_mask'].long().to(device)\n",
    "        gold_label = batch['rating'].to(device)\n",
    "        outputs = model(input_ids, attn_masks)\n",
    "        \n",
    "        gold_labels.extend(gold_label.cpu().numpy())\n",
    "\n",
    "        loss = loss_fn(outputs, gold_label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted_labels = torch.max(outputs, dim=1)\n",
    "        \n",
    "        predictions.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "        for i in range(len(predicted_labels)):\n",
    "            if predicted_labels[i] != gold_label[i]:\n",
    "                misclassification = f\"{batch['word'][i]} predicted as {predicted_labels[i]} instead of {gold_label[i]}\"\n",
    "                misclassifications.append(misclassification)\n",
    "    \n",
    "average_loss = total_loss / len(dataloader)\n",
    "print(f'Average Loss: {average_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.34      0.38       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.36      0.80      0.50       100\n",
      "\n",
      "    accuracy                           0.38       300\n",
      "   macro avg       0.26      0.38      0.29       300\n",
      "weighted avg       0.26      0.38      0.29       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(gold_labels, predictions)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Just_Words_Dataset(Dataset):\n",
    "    def __init__(self, words_file, tokenizer, regression=False):\n",
    "        self.words_file = words_file\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.data = pd.read_csv(words_file)\n",
    "        self.words = self.data['word'].to_list()\n",
    "        self.encodings = self.tokenizer([word for word in self.words], add_special_tokens=True, padding='longest', return_tensors='pt')\n",
    "        \n",
    "        self.labels = self.data['tag'].to_list()\n",
    "        if regression == True:\n",
    "            self.ratings = self.data['rating'].to_list()\n",
    "        else:\n",
    "            ratings = self.data['rating'].to_list()\n",
    "            self.ratings = map_values(ratings, self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        item = {'word': self.words[idx], 'input_ids': self.encodings['input_ids'][idx], 'attn_mask': self.encodings['attention_mask'][idx], 'token_type_ids': self.encodings['token_type_ids'], 'rating': self.ratings[idx],'label': self.labels[idx]}\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(csv_file):\n",
    "    \n",
    "    file = pd.read_csv(csv_file)\n",
    "    \n",
    "    print(\"total words:\",len(file))\n",
    "    randomized_data = file.sample(frac=1, random_state=42)\n",
    "    print(\"total randomized words:\",len(randomized_data))\n",
    "\n",
    "    train = int(len(randomized_data) * 0.8)\n",
    "\n",
    "    train_data = randomized_data[:train]\n",
    "    print(\"total training set:\",len(train_data))\n",
    "\n",
    "    test_data = randomized_data[train:]\n",
    "    print(\"total testing set:\",len(test_data))\n",
    "\n",
    "    train_filepath = \"train_dataset.csv\"\n",
    "    test_filepath = \"test_dataset.csv\"\n",
    "    train_data.to_csv(train_filepath, index=False)\n",
    "    test_data.to_csv(test_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 300\n",
      "total randomized words: 300\n",
      "total training set: 240\n",
      "total testing set: 60\n"
     ]
    }
   ],
   "source": [
    "split_dataset('merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Multimodal_Dataset('train_dataset.csv', 'images', tokenizer=tokenizer)\n",
    "test_data = Multimodal_Dataset('test_dataset.csv', 'images', tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': ['simplification', 'spotter', 'peacetime', 'hill', 'decontamination', 'deflator', 'diatribe', 'backhandedness'], 'input_ids': tensor([[  101, 21934, 24759,  9031,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  3962,  3334,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  3521,  7292,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2940,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 21933, 12380, 22311,  3508,   102,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 13366, 20051,  2953,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 22939, 18886,  4783,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2067, 11774,  2098,  2791,   102,     0,     0,     0,     0,\n",
      "             0,     0]]), 'attn_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]]), 'visual_embeddings': tensor([[[[[1.0022]],\n",
      "\n",
      "          [[0.8306]],\n",
      "\n",
      "          [[0.4395]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.1831]],\n",
      "\n",
      "          [[0.0612]],\n",
      "\n",
      "          [[0.3710]]],\n",
      "\n",
      "\n",
      "         [[[0.1260]],\n",
      "\n",
      "          [[0.7093]],\n",
      "\n",
      "          [[0.2115]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0000]],\n",
      "\n",
      "          [[0.0067]],\n",
      "\n",
      "          [[0.5270]]],\n",
      "\n",
      "\n",
      "         [[[1.3592]],\n",
      "\n",
      "          [[0.2416]],\n",
      "\n",
      "          [[0.3206]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0249]],\n",
      "\n",
      "          [[0.0291]],\n",
      "\n",
      "          [[0.6485]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.1944]],\n",
      "\n",
      "          [[1.0095]],\n",
      "\n",
      "          [[0.0654]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0072]],\n",
      "\n",
      "          [[0.0000]],\n",
      "\n",
      "          [[0.2217]]],\n",
      "\n",
      "\n",
      "         [[[1.3275]],\n",
      "\n",
      "          [[0.6572]],\n",
      "\n",
      "          [[0.0000]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0200]],\n",
      "\n",
      "          [[0.1488]],\n",
      "\n",
      "          [[0.7218]]],\n",
      "\n",
      "\n",
      "         [[[0.4250]],\n",
      "\n",
      "          [[0.1252]],\n",
      "\n",
      "          [[0.1390]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0018]],\n",
      "\n",
      "          [[0.0089]],\n",
      "\n",
      "          [[0.2928]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.3630]],\n",
      "\n",
      "          [[0.5112]],\n",
      "\n",
      "          [[0.4257]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.5152]],\n",
      "\n",
      "          [[0.4761]],\n",
      "\n",
      "          [[0.3189]]],\n",
      "\n",
      "\n",
      "         [[[0.3661]],\n",
      "\n",
      "          [[0.3416]],\n",
      "\n",
      "          [[0.3404]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0309]],\n",
      "\n",
      "          [[0.1561]],\n",
      "\n",
      "          [[0.3530]]],\n",
      "\n",
      "\n",
      "         [[[0.7191]],\n",
      "\n",
      "          [[0.3997]],\n",
      "\n",
      "          [[0.2191]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0449]],\n",
      "\n",
      "          [[0.0351]],\n",
      "\n",
      "          [[0.5866]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.4083]],\n",
      "\n",
      "          [[0.0232]],\n",
      "\n",
      "          [[0.0508]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0674]],\n",
      "\n",
      "          [[0.0383]],\n",
      "\n",
      "          [[0.0123]]],\n",
      "\n",
      "\n",
      "         [[[0.4083]],\n",
      "\n",
      "          [[0.0232]],\n",
      "\n",
      "          [[0.0508]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0674]],\n",
      "\n",
      "          [[0.0383]],\n",
      "\n",
      "          [[0.0123]]],\n",
      "\n",
      "\n",
      "         [[[0.4083]],\n",
      "\n",
      "          [[0.0232]],\n",
      "\n",
      "          [[0.0508]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0674]],\n",
      "\n",
      "          [[0.0383]],\n",
      "\n",
      "          [[0.0123]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.2570]],\n",
      "\n",
      "          [[0.4955]],\n",
      "\n",
      "          [[1.2634]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0204]],\n",
      "\n",
      "          [[0.1706]],\n",
      "\n",
      "          [[1.0943]]],\n",
      "\n",
      "\n",
      "         [[[0.1039]],\n",
      "\n",
      "          [[0.2340]],\n",
      "\n",
      "          [[1.0918]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0044]],\n",
      "\n",
      "          [[0.0347]],\n",
      "\n",
      "          [[0.2015]]],\n",
      "\n",
      "\n",
      "         [[[0.0169]],\n",
      "\n",
      "          [[0.4488]],\n",
      "\n",
      "          [[0.0193]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.5016]],\n",
      "\n",
      "          [[0.0795]],\n",
      "\n",
      "          [[0.0565]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.0238]],\n",
      "\n",
      "          [[0.1494]],\n",
      "\n",
      "          [[0.0681]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0077]],\n",
      "\n",
      "          [[0.2253]],\n",
      "\n",
      "          [[0.0817]]],\n",
      "\n",
      "\n",
      "         [[[0.3838]],\n",
      "\n",
      "          [[0.0625]],\n",
      "\n",
      "          [[0.0706]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.1001]],\n",
      "\n",
      "          [[0.1298]],\n",
      "\n",
      "          [[0.1494]]],\n",
      "\n",
      "\n",
      "         [[[0.4083]],\n",
      "\n",
      "          [[0.0232]],\n",
      "\n",
      "          [[0.0508]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0674]],\n",
      "\n",
      "          [[0.0383]],\n",
      "\n",
      "          [[0.0123]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.8360]],\n",
      "\n",
      "          [[0.0713]],\n",
      "\n",
      "          [[0.4793]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0972]],\n",
      "\n",
      "          [[0.0627]],\n",
      "\n",
      "          [[0.4958]]],\n",
      "\n",
      "\n",
      "         [[[0.3847]],\n",
      "\n",
      "          [[0.0582]],\n",
      "\n",
      "          [[0.0059]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0507]],\n",
      "\n",
      "          [[0.0786]],\n",
      "\n",
      "          [[0.5644]]],\n",
      "\n",
      "\n",
      "         [[[0.1500]],\n",
      "\n",
      "          [[0.0515]],\n",
      "\n",
      "          [[0.0430]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0466]],\n",
      "\n",
      "          [[0.0998]],\n",
      "\n",
      "          [[0.2845]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.4083]],\n",
      "\n",
      "          [[0.0232]],\n",
      "\n",
      "          [[0.0508]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0674]],\n",
      "\n",
      "          [[0.0383]],\n",
      "\n",
      "          [[0.0123]]],\n",
      "\n",
      "\n",
      "         [[[0.4083]],\n",
      "\n",
      "          [[0.0232]],\n",
      "\n",
      "          [[0.0508]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0674]],\n",
      "\n",
      "          [[0.0383]],\n",
      "\n",
      "          [[0.0123]]],\n",
      "\n",
      "\n",
      "         [[[0.4083]],\n",
      "\n",
      "          [[0.0232]],\n",
      "\n",
      "          [[0.0508]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0674]],\n",
      "\n",
      "          [[0.0383]],\n",
      "\n",
      "          [[0.0123]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.3744]],\n",
      "\n",
      "          [[0.9183]],\n",
      "\n",
      "          [[0.2184]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.4181]],\n",
      "\n",
      "          [[0.5256]],\n",
      "\n",
      "          [[1.3308]]],\n",
      "\n",
      "\n",
      "         [[[0.7685]],\n",
      "\n",
      "          [[1.3435]],\n",
      "\n",
      "          [[0.1908]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.1862]],\n",
      "\n",
      "          [[0.1215]],\n",
      "\n",
      "          [[0.8340]]],\n",
      "\n",
      "\n",
      "         [[[0.0262]],\n",
      "\n",
      "          [[0.4160]],\n",
      "\n",
      "          [[0.3870]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.1875]],\n",
      "\n",
      "          [[0.0400]],\n",
      "\n",
      "          [[0.4022]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.4083]],\n",
      "\n",
      "          [[0.0232]],\n",
      "\n",
      "          [[0.0508]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0674]],\n",
      "\n",
      "          [[0.0383]],\n",
      "\n",
      "          [[0.0123]]],\n",
      "\n",
      "\n",
      "         [[[0.4083]],\n",
      "\n",
      "          [[0.0232]],\n",
      "\n",
      "          [[0.0508]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0674]],\n",
      "\n",
      "          [[0.0383]],\n",
      "\n",
      "          [[0.0123]]],\n",
      "\n",
      "\n",
      "         [[[0.4083]],\n",
      "\n",
      "          [[0.0232]],\n",
      "\n",
      "          [[0.0508]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0674]],\n",
      "\n",
      "          [[0.0383]],\n",
      "\n",
      "          [[0.0123]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.4838]],\n",
      "\n",
      "          [[0.0146]],\n",
      "\n",
      "          [[0.0732]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.6144]],\n",
      "\n",
      "          [[0.0088]],\n",
      "\n",
      "          [[0.1287]]],\n",
      "\n",
      "\n",
      "         [[[0.3748]],\n",
      "\n",
      "          [[0.7316]],\n",
      "\n",
      "          [[1.1426]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0644]],\n",
      "\n",
      "          [[0.7133]],\n",
      "\n",
      "          [[0.9405]]],\n",
      "\n",
      "\n",
      "         [[[0.4069]],\n",
      "\n",
      "          [[0.7119]],\n",
      "\n",
      "          [[0.3906]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.2758]],\n",
      "\n",
      "          [[0.1626]],\n",
      "\n",
      "          [[0.3120]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.4083]],\n",
      "\n",
      "          [[0.0232]],\n",
      "\n",
      "          [[0.0508]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0674]],\n",
      "\n",
      "          [[0.0383]],\n",
      "\n",
      "          [[0.0123]]],\n",
      "\n",
      "\n",
      "         [[[0.4083]],\n",
      "\n",
      "          [[0.0232]],\n",
      "\n",
      "          [[0.0508]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0674]],\n",
      "\n",
      "          [[0.0383]],\n",
      "\n",
      "          [[0.0123]]],\n",
      "\n",
      "\n",
      "         [[[0.4083]],\n",
      "\n",
      "          [[0.0232]],\n",
      "\n",
      "          [[0.0508]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0674]],\n",
      "\n",
      "          [[0.0383]],\n",
      "\n",
      "          [[0.0123]]]]], grad_fn=<StackBackward0>), 'rating': tensor([2, 1, 1, 0, 1, 1, 1, 1]), 'label': ['abstract', 'middle', 'middle', 'concrete', 'middle', 'middle', 'middle', 'middle']}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 loss: 1.1007295115788778\r"
     ]
    }
   ],
   "source": [
    "model = TEXTUAL_BERT(3).to(device)\n",
    "epochs = 20\n",
    "model.train()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        input_ids = batch['input_ids'].long().to(device)\n",
    "        attn_masks = batch['attn_mask'].long().to(device)\n",
    "        gold_label = batch['rating'].to(device)\n",
    "    \n",
    "        outputs = model(input_ids, attn_masks)\n",
    "\n",
    "        loss = loss_fn(outputs, gold_label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        print(\"epoch:\",epoch, \"loss:\", total_loss/(i+1), end='\\r')\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 1.0994298897291486\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "predictions = []\n",
    "gold_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = torch.Tensor(batch['input_ids']).long().to(device)\n",
    "        attn_masks = torch.Tensor(batch['attn_mask']).long().to(device)\n",
    "        gold_label = batch['rating'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attn_masks)\n",
    "       \n",
    "        gold_labels.extend(gold_label.cpu().numpy())\n",
    "\n",
    "        loss = loss_fn(outputs, gold_label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted_labels = torch.max(outputs, dim=1)\n",
    "        \n",
    "        predictions.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "average_loss = total_loss / len(test_dataloader)\n",
    "print(f'Average Loss: {average_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       371\n",
      "           1       0.00      0.00      0.00       414\n",
      "           2       0.35      1.00      0.51       415\n",
      "\n",
      "    accuracy                           0.35      1200\n",
      "   macro avg       0.12      0.33      0.17      1200\n",
      "weighted avg       0.12      0.35      0.18      1200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(gold_labels, predictions)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data = Multimodal_Dataset('merged_data.csv', 'images', tokenizer=tokenizer, regression=True)\n",
    "regression_dataloader = DataLoader(regression_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 9.560116449147326\n"
     ]
    }
   ],
   "source": [
    "model = TEXTUAL_BERT(1).to(device)\n",
    "total_loss = 0\n",
    "predictions = []\n",
    "gold_labels = []\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in regression_dataloader:\n",
    "        input_ids = torch.Tensor(batch['input_ids']).long().to(device)\n",
    "        attn_masks = torch.Tensor(batch['attn_mask']).long().to(device)\n",
    "        gold_label = batch['rating'].to(device)\n",
    "    \n",
    "        outputs = model(input_ids, attn_masks)\n",
    "        \n",
    "        gold_labels.extend(gold_label.cpu().numpy())\n",
    "\n",
    "        loss = loss_fn(outputs, gold_label.unsqueeze(1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted_labels = torch.max(outputs, dim=1)\n",
    "        #print(gold_label.size(), predicted_labels.size())\n",
    "        predictions.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "average_loss = total_loss / len(regression_dataloader)\n",
    "print(f'Average Loss: {average_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient: nan\n",
      "P-value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "correlation_coefficient, p_value = pearsonr(gold_labels, predictions)\n",
    "#The model sometimes predicts only one value and as a result the pearson correlation cannot be computed\n",
    "print(f\"Pearson Correlation Coefficient: {correlation_coefficient}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.2834\n",
      "MAE: 3.0588\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(gold_labels, predictions, squared=False)\n",
    "mae = mean_absolute_error(gold_labels, predictions)\n",
    "\n",
    "print(f\"MSE: {mse.item():.4f}\")\n",
    "print(f\"MAE: {mae.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visual BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VISUAL_BERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VISUAL_BERT, self).__init__()\n",
    "        self.visual_bert = VisualBertModel.from_pretrained(\"uclanlp/visualbert-vqa-coco-pre\")\n",
    "        self.classifier = nn.Linear(self.visual_bert.config.hidden_size, 3)\n",
    "\n",
    "    def forward(self, input_ids, attn_masks, token_type_ids, visual_embeddings):\n",
    "        \n",
    "        visual_token_type_ids = torch.ones(visual_embeddings.shape[:-1], dtype=torch.long).to(device)\n",
    "        visual_attention_mask = torch.ones(visual_embeddings.shape[:-1], dtype=torch.float).to(device)\n",
    "        \n",
    "        outputs = self.visual_bert(input_ids=input_ids, attention_mask=attn_masks, token_type_ids=token_type_ids, visual_embeds=visual_embeddings, visual_attention_mask=visual_attention_mask, visual_token_type_ids=visual_token_type_ids)\n",
    "        predictions = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 2.251596725781759\n"
     ]
    }
   ],
   "source": [
    "language_and_vision_model = VISUAL_BERT().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "language_and_vision_model.eval()\n",
    "total_loss = 0\n",
    "predictions_visual = []\n",
    "gold_labels_visual = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].long().to(device)\n",
    "        \n",
    "        attn_masks = batch['attn_mask'].long().to(device)\n",
    "        token_type_ids = torch.mean(batch['token_type_ids'].float(), dim=1).to(device)\n",
    "        token_type_ids = token_type_ids.long().to(device)\n",
    "        \n",
    "        visual_embeddings = batch['visual_embeddings'].to(device)\n",
    "        visual_embeddings = visual_embeddings.squeeze(3)\n",
    "        \n",
    "        gold_label = batch['rating'].to(device)\n",
    "\n",
    "        outputs = language_and_vision_model(input_ids, attn_masks, token_type_ids, visual_embeddings.squeeze(3))\n",
    "\n",
    "        gold_labels_visual.extend(gold_label.cpu().numpy())\n",
    "        \n",
    "        loss = loss_fn(outputs, gold_label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted_labels = torch.max(outputs, dim=1)\n",
    "        \n",
    "        predictions_visual.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "        loss = loss_fn(outputs, gold_label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "average_loss = total_loss / len(dataloader)\n",
    "print(f'Average Loss: {average_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       100\n",
      "           1       0.33      1.00      0.50       100\n",
      "           2       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.33       300\n",
      "   macro avg       0.11      0.33      0.17       300\n",
      "weighted avg       0.11      0.33      0.17       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(gold_labels_visual, predictions_visual)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 32.379753947257996\r"
     ]
    }
   ],
   "source": [
    "language_and_vision_model = VISUAL_BERT().to(device)\n",
    "epochs = 2\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(language_and_vision_model.parameters(), lr=1e-4)\n",
    "\n",
    "language_and_vision_model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        input_ids = batch['input_ids'].long().to(device)\n",
    "        attn_masks = batch['attn_mask'].long().to(device)\n",
    "        token_type_ids = torch.mean(batch['token_type_ids'].float(), dim=1).to(device)\n",
    "        token_type_ids = token_type_ids.long().to(device)\n",
    "        \n",
    "        visual_embeddings = batch['visual_embeddings'].to(device)\n",
    "        visual_embeddings = visual_embeddings.view(8, 12, 2048)\n",
    "        \n",
    "        gold_label = batch['rating'].to(device)\n",
    "    \n",
    "        outputs = language_and_vision_model(input_ids, attn_masks, token_type_ids, visual_embeddings)\n",
    "\n",
    "        loss = loss_fn(outputs, gold_label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        print(\"epoch:\",epoch, \"loss:\", total_loss/(i+1), end='\\r')\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 1.885128639539083\n"
     ]
    }
   ],
   "source": [
    "language_and_vision_model.eval()\n",
    "total_loss = 0\n",
    "predictions_visual = []\n",
    "gold_labels_visual = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].long().to(device)\n",
    "        \n",
    "        attn_masks = batch['attn_mask'].long().to(device)\n",
    "        token_type_ids = torch.mean(batch['token_type_ids'].float(), dim=1).to(device)\n",
    "        token_type_ids = token_type_ids.long().to(device)\n",
    "        \n",
    "        visual_embeddings = batch['visual_embeddings'].to(device)\n",
    "        visual_embeddings = visual_embeddings.view(4, 12, 2048)\n",
    "        \n",
    "        gold_label = batch['rating'].to(device)\n",
    "\n",
    "        outputs = language_and_vision_model(input_ids, attn_masks, token_type_ids, visual_embeddings)\n",
    "\n",
    "        gold_labels_visual.extend(gold_label.cpu().numpy())\n",
    "        \n",
    "        loss = loss_fn(outputs, gold_label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted_labels = torch.max(outputs, dim=1)\n",
    "        \n",
    "        predictions_visual.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "        loss = loss_fn(outputs, gold_label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "average_loss = total_loss / len(dataloader)\n",
    "print(f'Average Loss: {average_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.99      0.65       100\n",
      "           1       0.73      0.08      0.14       100\n",
      "           2       0.76      0.64      0.70       100\n",
      "\n",
      "    accuracy                           0.57       300\n",
      "   macro avg       0.66      0.57      0.50       300\n",
      "weighted avg       0.66      0.57      0.50       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(gold_labels_visual, predictions_visual)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AICS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
