{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from transformers import BertTokenizer, DistilBertModel, VisualBertModel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast, os\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "batch_size = 4\n",
    "device = torch.device('cuda:2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_values(ratings, tags):\n",
    "    for i, tag in enumerate(tags):\n",
    "        if tag == 'concrete':\n",
    "            ratings[i] = 0\n",
    "        elif tag == 'middle':\n",
    "            ratings[i] = 1\n",
    "        else:\n",
    "            ratings[i] = 2\n",
    "    return ratings\n",
    "\n",
    "class Multimodal_Dataset(Dataset):\n",
    "    def __init__(self, words_file, image_file, tokenizer):\n",
    "        self.words_file = words_file\n",
    "        self.images = image_file\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.data = pd.read_csv(words_file)\n",
    "        self.words = self.data['word'].to_list()\n",
    "        self.encodings = self.tokenizer([word for word in self.words], add_special_tokens=True, padding='longest', return_tensors='pt')\n",
    "\n",
    "        self.photos = self.data['photos'].apply(ast.literal_eval)\n",
    "        self.labels = self.data['tag'].to_list()\n",
    "        ratings = self.data['rating'].to_list()\n",
    "        self.ratings = map_values(ratings, self.labels)\n",
    "        \n",
    "\n",
    "        transform_list = [\n",
    "            transforms.Grayscale(1),\n",
    "            transforms.Resize((32, 168)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ]\n",
    "        self.transform = transforms.Compose(transform_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images = self.photos[idx]\n",
    "        imgs = []\n",
    "        for image in images:\n",
    "          img_path = os.path.join('images/', image)\n",
    "          img = Image.open(img_path).convert('RGB')\n",
    "          img = self.transform(img)\n",
    "          imgs.append(img)\n",
    "\n",
    "        #padding list of images, without this the dataloader results in errors\n",
    "        while len(imgs) < 12:\n",
    "            imgs.append(torch.zeros_like(imgs[0]))\n",
    "\n",
    "        #print(f\"Word: {self.words[idx]}, Number of images: {len(images)}\")\n",
    "\n",
    "        item = {'word': self.words[idx], 'input_ids': self.encodings['input_ids'][idx], 'attn_mask': self.encodings['attention_mask'][idx], 'token_type_ids': self.encodings['token_type_ids'],'imgs': imgs, 'rating': self.ratings[idx],'label': self.labels[idx]}\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'rack',\n",
       " 'input_ids': tensor([  101, 14513,   102,     0,     0,     0,     0]),\n",
       " 'attn_mask': tensor([1, 1, 1, 0, 0, 0, 0]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'imgs': [tensor([[[-0.3647, -0.3412, -0.3333,  ..., -0.2078, -0.1843, -0.2000],\n",
       "           [-0.3255, -0.3098, -0.3020,  ..., -0.1373, -0.1216, -0.1529],\n",
       "           [-0.2941, -0.2784, -0.2549,  ..., -0.1294, -0.0510, -0.0431],\n",
       "           ...,\n",
       "           [-0.7412, -0.7333, -0.7098,  ..., -0.5059, -0.5059, -0.5373],\n",
       "           [-0.7098, -0.7020, -0.6706,  ..., -0.5294, -0.4745, -0.4667],\n",
       "           [-0.6235, -0.6549, -0.6549,  ..., -0.5373, -0.5137, -0.5843]]]),\n",
       "  tensor([[[-0.8275, -0.8588, -0.9059,  ..., -0.4431, -0.3961, -0.4353],\n",
       "           [-0.7569, -0.7961, -0.8353,  ..., -0.1451, -0.3020, -0.4196],\n",
       "           [-0.5137, -0.6000, -0.6549,  ..., -0.0667, -0.2471, -0.2784],\n",
       "           ...,\n",
       "           [-0.3647, -0.3255, -0.3647,  ...,  0.4118,  0.3961,  0.1373],\n",
       "           [-0.5137, -0.5137, -0.5529,  ..., -0.1608, -0.0824, -0.0902],\n",
       "           [-0.2784, -0.3961, -0.3961,  ..., -0.5294, -0.5765, -0.6000]]]),\n",
       "  tensor([[[ 0.4510,  0.4510,  0.4588,  ..., -0.6941, -0.6549, -0.6549],\n",
       "           [ 0.4824,  0.4824,  0.4902,  ..., -0.7412, -0.6784, -0.6314],\n",
       "           [ 0.5294,  0.5294,  0.5294,  ..., -0.7569, -0.7176, -0.6471],\n",
       "           ...,\n",
       "           [-0.1059, -0.1137, -0.1451,  ..., -0.0510, -0.0824, -0.0667],\n",
       "           [-0.0745, -0.0745, -0.1294,  ..., -0.3882, -0.3569, -0.2157],\n",
       "           [-0.2000, -0.2000, -0.2471,  ..., -0.6627, -0.6627, -0.6235]]]),\n",
       "  tensor([[[0.4275, 0.4353, 0.4353,  ..., 0.4431, 0.4431, 0.4431],\n",
       "           [0.4275, 0.4353, 0.4353,  ..., 0.4431, 0.4431, 0.4431],\n",
       "           [0.4275, 0.4353, 0.4353,  ..., 0.4431, 0.4431, 0.4431],\n",
       "           ...,\n",
       "           [0.4196, 0.4196, 0.4196,  ..., 0.4353, 0.4353, 0.4353],\n",
       "           [0.4196, 0.4275, 0.4275,  ..., 0.4353, 0.4275, 0.4275],\n",
       "           [0.4196, 0.4275, 0.4275,  ..., 0.4275, 0.4275, 0.4275]]]),\n",
       "  tensor([[[-1.0000, -1.0000, -1.0000,  ..., -0.2706, -0.2784, -0.2157],\n",
       "           [-0.9765, -0.9922, -1.0000,  ..., -0.2706, -0.3490, -0.3020],\n",
       "           [-0.8353, -0.8902, -0.9373,  ..., -0.1608, -0.2314, -0.2392],\n",
       "           ...,\n",
       "           [ 0.0745,  0.1137,  0.1451,  ...,  0.2157,  0.2078,  0.1137],\n",
       "           [ 0.1373,  0.1451,  0.0980,  ...,  0.1608,  0.1529,  0.1373],\n",
       "           [ 0.0902,  0.0196, -0.0667,  ...,  0.1922,  0.0980,  0.0902]]]),\n",
       "  tensor([[[ 0.0275, -0.1137, -0.4275,  ...,  0.9843,  0.9294,  0.8510],\n",
       "           [ 0.3569,  0.3098, -0.2471,  ...,  0.9451,  0.9765,  0.9216],\n",
       "           [ 0.0824,  0.0980,  0.1294,  ...,  0.6157,  0.7333,  0.7333],\n",
       "           ...,\n",
       "           [-0.6863, -0.6471, -0.7333,  ..., -0.3490, -0.4745, -0.6235],\n",
       "           [-0.7176, -0.7176, -0.7098,  ..., -0.5451, -0.5843, -0.5373],\n",
       "           [-0.5922, -0.6157, -0.4902,  ..., -0.7804, -0.7412, -0.6549]]]),\n",
       "  tensor([[[-0.8902, -0.6549, -0.5843,  ..., -0.7804, -0.7804, -0.7882],\n",
       "           [-0.8980, -0.2863, -0.1608,  ..., -0.7569, -0.6471, -0.4353],\n",
       "           [-0.7961, -0.0431,  0.2000,  ..., -0.4667, -0.1059,  0.1294],\n",
       "           ...,\n",
       "           [ 0.1529, -0.1216, -0.3725,  ..., -0.2235, -0.1608,  0.0039],\n",
       "           [ 0.5608, -0.3490, -0.8196,  ..., -0.4510, -0.3098, -0.0275],\n",
       "           [-0.1137, -0.6000, -0.8510,  ..., -0.4902, -0.3490, -0.0431]]]),\n",
       "  tensor([[[ 0.9765,  0.9843,  0.9843,  ...,  0.9608,  0.9529,  0.9451],\n",
       "           [ 0.9843,  0.9765,  0.9765,  ...,  0.9608,  0.9529,  0.9451],\n",
       "           [ 0.9843,  0.9765,  0.9765,  ...,  0.9529,  0.9529,  0.9451],\n",
       "           ...,\n",
       "           [-0.3725, -0.3961, -0.4588,  ..., -0.4588, -0.4745, -0.4745],\n",
       "           [-0.4039, -0.4431, -0.4510,  ..., -0.4588, -0.5451, -0.4980],\n",
       "           [-0.4118, -0.4431, -0.4588,  ..., -0.4353, -0.5137, -0.4745]]]),\n",
       "  tensor([[[ 0.1765,  0.1765,  0.2000,  ...,  0.1765,  0.1608,  0.1451],\n",
       "           [ 0.2314,  0.2314,  0.2471,  ...,  0.2235,  0.2078,  0.2000],\n",
       "           [ 0.2706,  0.2706,  0.2941,  ...,  0.2627,  0.2471,  0.2471],\n",
       "           ...,\n",
       "           [-0.0353, -0.0039,  0.0824,  ..., -0.6078, -0.6078, -0.6078],\n",
       "           [-0.6784, -0.6863, -0.4745,  ..., -0.8039, -0.8039, -0.8118],\n",
       "           [-0.7333, -0.7255, -0.6078,  ..., -0.8196, -0.8196, -0.8275]]]),\n",
       "  tensor([[[-0.4118, -0.3961, -0.3882,  ..., -0.5608, -0.4745, -0.5059],\n",
       "           [-0.3804, -0.3647, -0.3569,  ..., -0.4824, -0.4118, -0.4431],\n",
       "           [-0.3412, -0.3255, -0.3176,  ..., -0.3882, -0.3490, -0.3804],\n",
       "           ...,\n",
       "           [-0.3333, -0.3255, -0.3255,  ...,  0.2314,  0.2000,  0.1373],\n",
       "           [-0.3804, -0.3725, -0.3647,  ..., -0.0353, -0.0510, -0.0275],\n",
       "           [-0.4275, -0.4118, -0.4039,  ...,  0.6157,  0.6000,  0.5529]]]),\n",
       "  tensor([[[ 0.1686,  0.2392,  0.3176,  ..., -0.8118, -0.8118, -0.7882],\n",
       "           [ 0.5608,  0.6314,  0.6941,  ..., -0.8902, -0.8824, -0.8824],\n",
       "           [ 0.5608,  0.6392,  0.7020,  ..., -0.8745, -0.8667, -0.8667],\n",
       "           ...,\n",
       "           [-0.7412, -0.7333, -0.7176,  ..., -0.3020, -0.3882, -0.4431],\n",
       "           [-0.7569, -0.7490, -0.7412,  ..., -0.4667, -0.4902, -0.4980],\n",
       "           [-0.6784, -0.7255, -0.7412,  ..., -0.5059, -0.5373, -0.5922]]]),\n",
       "  tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]])],\n",
       " 'rating': 0,\n",
       " 'label': 'concrete'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Multimodal_Dataset('merged_data.csv', 'images', tokenizer=tokenizer)\n",
    "data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': ['bladder', 'monocle', 'text', 'exhaustiveness'], 'input_ids': tensor([[  101, 24176,   102,     0,     0,     0,     0],\n",
      "        [  101, 18847, 14321,   102,     0,     0,     0],\n",
      "        [  101,  3793,   102,     0,     0,     0,     0],\n",
      "        [  101, 15095,  3512,  2791,   102,     0,     0]]), 'attn_mask': tensor([[1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]]), 'imgs': [tensor([[[[-0.4196, -0.3176, -0.2000,  ..., -0.4667, -0.2627, -0.1529],\n",
      "          [-0.2392, -0.1137, -0.0431,  ..., -0.5608, -0.3569, -0.2157],\n",
      "          [-0.2157, -0.0510,  0.0275,  ..., -0.6471, -0.6000, -0.5765],\n",
      "          ...,\n",
      "          [-0.4039, -0.3490, -0.2549,  ..., -0.2157, -0.2392, -0.1608],\n",
      "          [-0.3176, -0.2235, -0.1216,  ..., -0.7961, -0.7725, -0.7098],\n",
      "          [-0.2549, -0.1294, -0.0118,  ..., -0.8510, -0.8353, -0.8039]]],\n",
      "\n",
      "\n",
      "        [[[-0.5529, -0.3961, -0.2078,  ..., -0.5608, -0.5686, -0.5843],\n",
      "          [-0.4275, -0.3333, -0.2941,  ..., -0.5451, -0.5451, -0.5686],\n",
      "          [-0.2314, -0.2392, -0.2706,  ..., -0.5529, -0.5451, -0.5608],\n",
      "          ...,\n",
      "          [-0.7020, -0.7961, -0.7961,  ..., -0.5686, -0.5608, -0.5843],\n",
      "          [-0.8196, -0.7882, -0.7098,  ..., -0.5294, -0.5373, -0.5765],\n",
      "          [-0.7333, -0.7255, -0.7333,  ..., -0.6314, -0.6471, -0.6549]]],\n",
      "\n",
      "\n",
      "        [[[-0.1686, -0.1686, -0.1373,  ..., -0.1294, -0.1451, -0.1373],\n",
      "          [-0.1451, -0.1608, -0.1686,  ..., -0.0824, -0.0980, -0.0902],\n",
      "          [-0.2000, -0.2000, -0.2000,  ..., -0.0980, -0.0902, -0.1059],\n",
      "          ...,\n",
      "          [-0.8667, -0.8588, -0.8745,  ..., -0.6235, -0.6157, -0.6000],\n",
      "          [-0.7725, -0.7569, -0.7804,  ..., -0.6235, -0.6000, -0.6000],\n",
      "          [-0.5843, -0.5922, -0.5922,  ..., -0.8039, -0.7647, -0.7569]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4588,  0.4510,  0.0118,  ...,  0.0118,  0.0039, -0.1608],\n",
      "          [ 0.3176,  0.5765,  0.3020,  ...,  0.3333,  0.3020,  0.0824],\n",
      "          [ 0.0588,  0.4510,  0.3804,  ...,  0.2078,  0.1843, -0.0275],\n",
      "          ...,\n",
      "          [-0.5216, -0.4275, -0.4353,  ..., -0.5137, -0.5059, -0.5922],\n",
      "          [-0.4980, -0.4196, -0.4039,  ..., -0.5137, -0.4902, -0.5529],\n",
      "          [-0.5451, -0.4431, -0.4431,  ..., -0.5686, -0.5373, -0.5922]]]]), tensor([[[[ 0.3961,  0.4275,  0.3882,  ...,  0.3804,  0.1843,  0.0667],\n",
      "          [ 0.4510,  0.4196,  0.3725,  ...,  0.1451,  0.2627,  0.2627],\n",
      "          [ 0.4118,  0.4275,  0.4667,  ..., -0.0196,  0.0353,  0.1529],\n",
      "          ...,\n",
      "          [-0.0118, -0.0275, -0.0275,  ...,  0.4275,  0.5451,  0.7176],\n",
      "          [ 0.4745,  0.4431,  0.3882,  ...,  0.7255,  0.8431,  0.7961],\n",
      "          [ 0.5216,  0.5216,  0.5294,  ...,  0.7961,  0.7412,  0.6706]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3176,  0.3647,  0.1922,  ..., -0.6863, -0.7176, -0.8824],\n",
      "          [-0.1529, -0.0510,  0.0118,  ..., -0.8824, -0.9137, -0.9529],\n",
      "          [-0.1137,  0.0118,  0.0353,  ..., -0.6941, -0.7333, -0.8353],\n",
      "          ...,\n",
      "          [-0.0353, -0.0431, -0.0353,  ..., -0.1216, -0.1529, -0.1451],\n",
      "          [ 0.1765,  0.0980,  0.1059,  ..., -0.1059, -0.0196,  0.0039],\n",
      "          [ 0.0745, -0.0196,  0.0118,  ...,  0.0196, -0.0118,  0.0039]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6941,  0.7020,  0.7020,  ...,  0.6157,  0.6078,  0.6000],\n",
      "          [ 0.7098,  0.7176,  0.7176,  ...,  0.6314,  0.6235,  0.6235],\n",
      "          [ 0.7255,  0.7255,  0.7333,  ...,  0.6314,  0.6314,  0.6314],\n",
      "          ...,\n",
      "          [ 0.8745,  0.8745,  0.8745,  ...,  0.6392,  0.4667,  0.2941],\n",
      "          [ 0.8745,  0.8745,  0.8667,  ...,  0.4588,  0.4196,  0.4039],\n",
      "          [ 0.8667,  0.8588,  0.8510,  ...,  0.5294,  0.5529,  0.5843]]],\n",
      "\n",
      "\n",
      "        [[[-0.4824, -0.4902, -0.5216,  ...,  0.0667,  0.0353,  0.0745],\n",
      "          [-0.5059, -0.5059, -0.5294,  ..., -0.0824, -0.0745, -0.1529],\n",
      "          [-0.5451, -0.5059, -0.5373,  ..., -0.4980, -0.5059, -0.4588],\n",
      "          ...,\n",
      "          [-0.5216, -0.4745, -0.4431,  ..., -0.5216, -0.5137, -0.5059],\n",
      "          [-0.5137, -0.5137, -0.5373,  ..., -0.4039, -0.3176, -0.4588],\n",
      "          [-0.5137, -0.5373, -0.5294,  ..., -0.3725, -0.3569, -0.4510]]]]), tensor([[[[-0.9529, -0.9529, -0.9529,  ..., -0.9373, -0.9529, -0.9529],\n",
      "          [-0.9451, -0.9373, -0.9451,  ..., -0.9216, -0.9373, -0.9608],\n",
      "          [-0.9373, -0.9373, -0.9529,  ..., -0.9451, -0.9451, -0.9451],\n",
      "          ...,\n",
      "          [-0.9451, -0.9529, -0.9451,  ..., -0.9451, -0.9451, -0.9373],\n",
      "          [-0.9216, -0.9294, -0.9294,  ..., -0.9451, -0.9529, -0.9373],\n",
      "          [-0.9294, -0.9373, -0.9451,  ..., -0.9608, -0.9686, -0.9686]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  0.9922,  0.7255,  ...,  0.8588,  1.0000,  1.0000],\n",
      "          [ 1.0000,  0.9922,  0.6157,  ...,  0.7961,  1.0000,  1.0000],\n",
      "          [ 1.0000,  0.9922,  0.6078,  ...,  0.8039,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  0.9922,  0.6078,  ...,  0.7804,  1.0000,  1.0000],\n",
      "          [ 1.0000,  0.9922,  0.6078,  ...,  0.7804,  1.0000,  1.0000],\n",
      "          [ 1.0000,  0.9922,  0.7333,  ...,  0.8510,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.7569, -0.7412, -0.7412,  ..., -0.8431, -0.8118, -0.8980],\n",
      "          [-0.7647, -0.7255, -0.7333,  ..., -0.8510, -0.7961, -0.9059],\n",
      "          [-0.7490, -0.7098, -0.7255,  ..., -0.8745, -0.7961, -0.9059],\n",
      "          ...,\n",
      "          [ 0.3255,  0.3333,  0.3333,  ..., -0.0902, -0.0980, -0.0980],\n",
      "          [ 0.0510,  0.0510,  0.0588,  ..., -0.1922, -0.2000, -0.1922],\n",
      "          [-0.0275, -0.0196, -0.0196,  ..., -0.5059, -0.5373, -0.5294]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 0.0980,  0.0902,  0.0902,  ...,  0.1059,  0.0980,  0.0980],\n",
      "          [ 0.0980,  0.0980,  0.0980,  ...,  0.0980,  0.0980,  0.1059],\n",
      "          [ 0.0980,  0.0902,  0.0902,  ...,  0.0980,  0.0980,  0.1059]]]]), tensor([[[[-0.8745, -0.8510, -0.7961,  ..., -0.9373, -0.9137, -0.9137],\n",
      "          [-0.8745, -0.8510, -0.7961,  ..., -0.9451, -0.9294, -0.9216],\n",
      "          [-0.8902, -0.8667, -0.7961,  ..., -0.9216, -0.9137, -0.9373],\n",
      "          ...,\n",
      "          [-0.7882, -0.7804, -0.7804,  ..., -0.4745, -0.4824, -0.4745],\n",
      "          [-0.5843, -0.5843, -0.5843,  ..., -0.3569, -0.3569, -0.3647],\n",
      "          [-0.5686, -0.5608, -0.5608,  ..., -0.3490, -0.3333, -0.3098]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9373,  0.9373,  0.9451,  ...,  0.9843,  0.9294,  0.8196],\n",
      "          [ 0.9529,  0.9529,  0.9529,  ...,  0.9922,  0.9843,  0.9451],\n",
      "          [ 0.9529,  0.9451,  0.9529,  ...,  0.9843,  0.9843,  0.9765],\n",
      "          ...,\n",
      "          [ 0.9608,  0.9608,  0.9608,  ...,  0.9765,  0.9765,  0.9843],\n",
      "          [ 0.9373,  0.9451,  0.9451,  ...,  0.9765,  0.9765,  0.9765],\n",
      "          [ 0.9216,  0.9294,  0.9294,  ...,  0.9686,  0.9686,  0.9608]]],\n",
      "\n",
      "\n",
      "        [[[-0.1843, -0.1922, -0.2157,  ..., -0.1373,  0.6392,  0.9843],\n",
      "          [-0.1686, -0.1843, -0.1922,  ..., -0.1451,  0.6314,  0.9922],\n",
      "          [-0.1608, -0.1843, -0.2000,  ..., -0.1608,  0.6157,  0.9843],\n",
      "          ...,\n",
      "          [-0.1608, -0.1765, -0.1922,  ..., -0.2000,  0.3098,  0.9608],\n",
      "          [-0.1373, -0.1529, -0.1686,  ..., -0.1922,  0.3020,  0.9608],\n",
      "          [-0.0980, -0.1137, -0.1451,  ..., -0.1765,  0.3098,  0.9765]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0745,  0.0745,  0.0902,  ..., -0.0902, -0.0902, -0.0902],\n",
      "          [ 0.0980,  0.0980,  0.1059,  ..., -0.0824, -0.0824, -0.0902],\n",
      "          [ 0.1059,  0.1059,  0.1216,  ..., -0.0510, -0.0588, -0.0667],\n",
      "          ...,\n",
      "          [ 0.3176,  0.3176,  0.3176,  ..., -0.7961, -0.7961, -0.8039],\n",
      "          [ 0.3020,  0.3020,  0.2941,  ..., -0.8431, -0.8431, -0.8431],\n",
      "          [ 0.2706,  0.2863,  0.2706,  ..., -0.7020, -0.6863, -0.6941]]]]), tensor([[[[-0.7647, -0.6627, -0.6235,  ..., -0.9373, -0.9373, -0.9373],\n",
      "          [-0.8353, -0.8588, -0.7804,  ..., -0.8902, -0.9137, -0.9294],\n",
      "          [-0.6471, -0.7255, -0.8275,  ..., -0.6235, -0.7255, -0.8118],\n",
      "          ...,\n",
      "          [-0.3725, -0.1922, -0.0980,  ...,  0.0902,  0.0902,  0.0745],\n",
      "          [-0.5059, -0.4510, -0.3882,  ..., -0.2549, -0.2706, -0.2784],\n",
      "          [-0.9059, -0.8980, -0.8824,  ..., -0.2784, -0.2941, -0.3020]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4980,  0.4510,  0.3412,  ..., -0.2078, -0.0745,  0.0588],\n",
      "          [ 0.4980,  0.6000,  0.4588,  ...,  0.1608,  0.1294,  0.0588],\n",
      "          [ 0.2314,  0.3176,  0.3255,  ...,  0.1451,  0.0745,  0.0902],\n",
      "          ...,\n",
      "          [-0.6627, -0.7647, -0.7725,  ..., -0.4039,  0.2235,  0.4745],\n",
      "          [-0.8196, -0.8510, -0.8118,  ..., -0.6235, -0.3412, -0.4039],\n",
      "          [-0.8353, -0.7961, -0.7725,  ..., -0.7882, -0.6863, -0.6392]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0431,  0.2549,  0.1373,  ...,  0.1451,  0.2235, -0.0588],\n",
      "          [ 0.1451,  0.2706,  0.1216,  ...,  0.1765,  0.1765, -0.0118],\n",
      "          [-0.4667, -0.4431, -0.4824,  ..., -0.7098, -0.7098, -0.6235],\n",
      "          ...,\n",
      "          [-0.5529, -0.6235, -0.6235,  ..., -0.7569, -0.7569, -0.6549],\n",
      "          [-0.5529, -0.6235, -0.6235,  ..., -0.7333, -0.7490, -0.6471],\n",
      "          [-0.5294, -0.5608, -0.5608,  ..., -0.6000, -0.7020, -0.6235]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6706,  0.9373,  0.9608,  ...,  0.9608,  0.9686,  0.9608],\n",
      "          [ 0.7020,  0.9373,  0.9529,  ...,  0.9686,  0.9686,  0.9686],\n",
      "          [ 0.7490,  0.9216,  0.9294,  ...,  0.9765,  0.9765,  0.9765],\n",
      "          ...,\n",
      "          [ 0.6078,  0.9608,  0.9765,  ...,  0.9686,  0.9686,  0.9765],\n",
      "          [ 0.6235,  0.9529,  0.9686,  ...,  0.9686,  0.9686,  0.9686],\n",
      "          [ 0.4431,  0.8824,  0.9137,  ...,  0.9216,  0.9216,  0.9216]]]]), tensor([[[[-0.5294, -0.4745, -0.4196,  ..., -0.4196, -0.4667, -0.4196],\n",
      "          [-0.5373, -0.5451, -0.4980,  ..., -0.4431, -0.4745, -0.4588],\n",
      "          [-0.4510, -0.4431, -0.4275,  ..., -0.3569, -0.3333, -0.4353],\n",
      "          ...,\n",
      "          [-0.4588, -0.4980, -0.5216,  ..., -0.3098, -0.0196,  0.1294],\n",
      "          [-0.5216, -0.4510, -0.4431,  ..., -0.0902, -0.1373, -0.0588],\n",
      "          [-0.4745, -0.4431, -0.4196,  ..., -0.1059, -0.3333, -0.4196]]],\n",
      "\n",
      "\n",
      "        [[[-0.9765, -0.9765, -0.9765,  ..., -0.9451, -0.9529, -0.9608],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9765, -0.9765, -0.9765],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.9451, -0.9373, -0.9294],\n",
      "          ...,\n",
      "          [-0.6314, -0.6235, -0.6078,  ..., -0.2235, -0.2392, -0.2471],\n",
      "          [-0.6784, -0.6863, -0.6863,  ..., -0.5843, -0.5451, -0.5216],\n",
      "          [-0.7333, -0.7490, -0.7412,  ..., -0.6549, -0.6784, -0.6784]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8196,  0.8431,  0.9216,  ...,  0.9765,  0.9216,  0.9059],\n",
      "          [ 0.9294,  0.9608,  0.9608,  ...,  0.9529,  0.9294,  0.8980],\n",
      "          [ 0.9529,  0.9765,  0.9608,  ...,  0.9451,  0.9216,  0.8745],\n",
      "          ...,\n",
      "          [ 0.9843,  0.9922,  0.9922,  ...,  0.9765,  0.9686,  0.9451],\n",
      "          [ 0.9843,  0.9922,  0.9922,  ...,  0.9686,  0.9686,  0.9608],\n",
      "          [ 0.9843,  0.9922,  0.9843,  ...,  0.9686,  0.9686,  0.9608]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2941,  0.3098,  0.3725,  ..., -0.4824, -0.5373, -0.6157],\n",
      "          [ 0.4667,  0.4745,  0.4902,  ..., -0.3882, -0.3804, -0.3882],\n",
      "          [ 0.4588,  0.4745,  0.4902,  ..., -0.4275, -0.3804, -0.3725],\n",
      "          ...,\n",
      "          [-0.2706, -0.3098, -0.3569,  ..., -0.1216, -0.1373, -0.1765],\n",
      "          [-0.4118, -0.4118, -0.4353,  ..., -0.1608, -0.1765, -0.1843],\n",
      "          [-0.4824, -0.4902, -0.5137,  ..., -0.2078, -0.1922, -0.1608]]]]), tensor([[[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1216,  0.1451,  0.1686,  ..., -0.2471, -0.2471, -0.2471],\n",
      "          [ 0.1529,  0.1843,  0.1922,  ..., -0.2784, -0.2627, -0.2549],\n",
      "          [ 0.1529,  0.1529,  0.1451,  ..., -0.3020, -0.3020, -0.2941],\n",
      "          ...,\n",
      "          [-0.2157, -0.2549, -0.2549,  ..., -0.6627, -0.6471, -0.6471],\n",
      "          [-0.3333, -0.3804, -0.3882,  ..., -0.6863, -0.6627, -0.6471],\n",
      "          [-0.1451, -0.2078, -0.3098,  ..., -0.6784, -0.6392, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-0.3176, -0.3255, -0.3333,  ..., -0.4980, -0.4980, -0.4745],\n",
      "          [-0.3020, -0.3098, -0.2941,  ..., -0.5059, -0.4824, -0.4902],\n",
      "          [-0.2471, -0.2627, -0.2549,  ..., -0.4510, -0.4745, -0.4824],\n",
      "          ...,\n",
      "          [-0.2863, -0.2784, -0.2863,  ..., -0.7333, -0.7176, -0.7098],\n",
      "          [-0.0353, -0.0353, -0.0353,  ..., -0.0824, -0.0824, -0.0667],\n",
      "          [-0.1922, -0.1608, -0.1608,  ..., -0.0039, -0.0275, -0.0275]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7020,  0.6941,  0.6941,  ...,  0.7412,  0.7490,  0.7412],\n",
      "          [ 0.7098,  0.7020,  0.6941,  ...,  0.7412,  0.7569,  0.7569],\n",
      "          [ 0.6784,  0.6863,  0.6941,  ...,  0.7255,  0.7333,  0.7255],\n",
      "          ...,\n",
      "          [ 0.9608,  0.9686,  0.9608,  ...,  0.9529,  0.9686,  0.9765],\n",
      "          [ 0.9686,  0.9686,  0.9686,  ...,  0.9843,  0.9843,  0.9843],\n",
      "          [ 0.9608,  0.9686,  0.9686,  ...,  0.9843,  0.9608,  0.9765]]]]), tensor([[[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0588, -0.0431, -0.1137,  ...,  0.5608,  0.5137,  0.6000],\n",
      "          [-0.1686, -0.3176, -0.3255,  ...,  0.6314,  0.5451,  0.6549],\n",
      "          [-0.0353, -0.1843, -0.2392,  ...,  0.6000,  0.5373,  0.6078],\n",
      "          ...,\n",
      "          [ 0.2392,  0.0667,  0.0824,  ...,  0.1529,  0.0588,  0.1137],\n",
      "          [ 0.3490,  0.3882,  0.4588,  ...,  0.2314,  0.2000,  0.2549],\n",
      "          [-0.2392, -0.1686, -0.0588,  ...,  0.1294,  0.1843,  0.2392]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1529,  0.4902,  0.8745,  ...,  0.9686,  0.9765,  0.9843],\n",
      "          [ 0.1059,  0.4902,  0.8510,  ...,  0.8353,  0.8667,  0.9294],\n",
      "          [ 0.0510,  0.5059,  0.8510,  ...,  0.8118,  0.8431,  0.8980],\n",
      "          ...,\n",
      "          [ 0.6314,  0.8353,  0.8353,  ...,  0.9294,  0.9922,  1.0000],\n",
      "          [ 0.6549,  0.8196,  0.8275,  ...,  0.9451,  0.9922,  1.0000],\n",
      "          [ 0.6235,  0.8118,  0.8039,  ...,  0.9216,  0.9608,  0.9608]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]]), tensor([[[[-0.0824, -0.1059, -0.1137,  ...,  0.0431,  0.0196, -0.0039],\n",
      "          [-0.3882, -0.4353, -0.4353,  ...,  0.2000,  0.1843,  0.1608],\n",
      "          [-0.1216, -0.1922, -0.2863,  ...,  0.1373,  0.1294,  0.1137],\n",
      "          ...,\n",
      "          [-0.5686, -0.5451, -0.5216,  ..., -0.1294, -0.1451, -0.1451],\n",
      "          [-0.5216, -0.4824, -0.4353,  ...,  0.0118,  0.0118,  0.0275],\n",
      "          [-0.5294, -0.5137, -0.4980,  ..., -0.0745, -0.0431, -0.0039]]],\n",
      "\n",
      "\n",
      "        [[[-0.9529, -0.9373, -0.9294,  ..., -0.8353, -0.8431, -0.8588],\n",
      "          [-0.9608, -0.9451, -0.9294,  ..., -0.8353, -0.8431, -0.8588],\n",
      "          [-0.9608, -0.9451, -0.9294,  ..., -0.8353, -0.8431, -0.8588],\n",
      "          ...,\n",
      "          [-0.8510, -0.8353, -0.8196,  ..., -0.7255, -0.7412, -0.7569],\n",
      "          [-0.7882, -0.7961, -0.8196,  ..., -0.7255, -0.7412, -0.7725],\n",
      "          [-0.8431, -0.8196, -0.8196,  ..., -0.7490, -0.7412, -0.7569]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]]), tensor([[[[ 0.8745,  0.8824,  0.8824,  ...,  0.7255,  0.7255,  0.7176],\n",
      "          [ 0.8824,  0.8824,  0.8902,  ...,  0.7333,  0.7333,  0.7255],\n",
      "          [ 0.8902,  0.8902,  0.8902,  ...,  0.7490,  0.7412,  0.7412],\n",
      "          ...,\n",
      "          [ 0.4588,  0.4431,  0.5216,  ..., -0.6471, -0.5451, -0.4667],\n",
      "          [-0.4980, -0.5765, -0.2627,  ..., -0.9216, -0.9059, -0.8353],\n",
      "          [-0.2863, -0.3020, -0.2627,  ..., -0.9059, -0.9059, -0.9059]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-0.2627, -0.2549, -0.2471,  ..., -0.5765, -0.5765, -0.5843],\n",
      "          [-0.2471, -0.2235, -0.2078,  ..., -0.6078, -0.6078, -0.6157],\n",
      "          [-0.2235, -0.2157, -0.2078,  ..., -0.6392, -0.6392, -0.6471]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]]), tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.2941, -0.2863, -0.2784,  ..., -0.5451, -0.5451, -0.5451],\n",
      "          [-0.2863, -0.2784, -0.2784,  ..., -0.5373, -0.5373, -0.5294],\n",
      "          [-0.2863, -0.2863, -0.2863,  ..., -0.5216, -0.5137, -0.5059],\n",
      "          ...,\n",
      "          [-0.8902, -0.8902, -0.8980,  ..., -0.8902, -0.8902, -0.8824],\n",
      "          [-0.8902, -0.8510, -0.7569,  ..., -0.8980, -0.8902, -0.8902],\n",
      "          [-0.8902, -0.8431, -0.6000,  ..., -0.9059, -0.8980, -0.8980]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]]), tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.9451, -0.9294, -0.9216,  ..., -0.8275, -0.8353, -0.8510],\n",
      "          [-0.9529, -0.9373, -0.9294,  ..., -0.8353, -0.8353, -0.8588],\n",
      "          [-0.9608, -0.9451, -0.9294,  ..., -0.8353, -0.8431, -0.8588],\n",
      "          ...,\n",
      "          [-0.8431, -0.8275, -0.8118,  ..., -0.7176, -0.7333, -0.7569],\n",
      "          [-0.7725, -0.7804, -0.8039,  ..., -0.7098, -0.7412, -0.7569],\n",
      "          [-0.8275, -0.8118, -0.7961,  ..., -0.7333, -0.7255, -0.7490]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])], 'rating': tensor([0, 1, 0, 2]), 'label': ['concrete', 'middle', 'concrete', 'abstract']}\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataloader):\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Textual BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEXTUAL_BERT(nn.Module):\n",
    "  def __init__(self):\n",
    "      super(TEXTUAL_BERT, self).__init__()\n",
    "      self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "      self.classifier = nn.Linear(self.bert.config.hidden_size, 3) #the number of out_features was set to 1 for a regression task\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "      outputs = self.bert(input_ids, attention_mask)\n",
    "      predictions = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
    "\n",
    "      return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 1.1174207242329914\n"
     ]
    }
   ],
   "source": [
    "model = TEXTUAL_BERT()#.to(device)\n",
    "\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "predictions = []\n",
    "gold_labels = []\n",
    "correct = 0\n",
    "samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        input_ids = torch.Tensor(batch['input_ids']).long()#.to(device)\n",
    "        attn_masks = torch.Tensor(batch['attn_mask']).long()#.to(device)\n",
    "        gold_label = batch['rating']#.to(device)\n",
    "    \n",
    "        outputs = model(input_ids, attn_masks)\n",
    "\n",
    "        gold_labels.extend(gold_label)\n",
    "\n",
    "        loss = loss_fn(outputs, gold_label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted_labels = torch.max(outputs, dim=1)\n",
    "        #print(gold_label.size(), predicted_labels.size())\n",
    "        predictions.extend(predicted_labels)\n",
    "        correct += (predicted_labels == gold_label).sum().item()\n",
    "        samples += len(gold_label)\n",
    "\n",
    "average_loss = total_loss / len(dataloader)\n",
    "print(f'Average Loss: {average_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = correct / samples\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       100\n",
      "           1       0.33      1.00      0.50       100\n",
      "           2       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.33       300\n",
      "   macro avg       0.11      0.33      0.17       300\n",
      "weighted avg       0.11      0.33      0.17       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(gold_labels, predictions)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse = mean_squared_error(gold_labels, predictions, squared=False)\n",
    "# mae = mean_absolute_error(gold_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.1823\n",
      "MAE: 2.9540\n"
     ]
    }
   ],
   "source": [
    "# print(f\"MSE: {mse.item():.4f}\")\n",
    "# print(f\"MAE: {mae.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visual BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VISUAL_BERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VISUAL_BERT, self).__init__()\n",
    "        self.bert_model = VisualBertModel.from_pretrained(\"uclanlp/visualbert-vqa-coco-pre\")\n",
    "        self.classifier = nn.Linear(self.bert_model.config.hidden_size, 1)\n",
    "\n",
    "        self.cnn_model = models.resnet50(pretrained=True)\n",
    "\n",
    "    def forward(self, input_ids, attn_masks, token_type_ids, images):\n",
    "        visual_embeddings = []\n",
    "        for img in images:\n",
    "            img_embedding = self.cnn_model(img)\n",
    "            visual_embeddings.append(img_embedding)\n",
    "        \n",
    "        visual_embeddings = torch.stack(visual_embeddings)\n",
    "\n",
    "        visual_token_type_ids = torch.ones(visual_embeddings.shape[:-1], dtype=torch.long).to(device)\n",
    "        visual_attention_mask = torch.ones(visual_embeddings.shape[:-1], dtype=torch.float).to(device)\n",
    "\n",
    "        outputs = self.bert_model(input_ids, attn_masks, token_type_ids, visual_embeddings, visual_token_type_ids, visual_attention_mask)\n",
    "        predictions = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusfilvi@GU.GU.SE/.conda/envs/AICS/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/gusfilvi@GU.GU.SE/.conda/envs/AICS/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m language_and_vision_model \u001b[38;5;241m=\u001b[39m \u001b[43mVISUAL_BERT\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      4\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "language_and_vision_model = VISUAL_BERT().to(device)\n",
    "\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "predictions = []\n",
    "gold_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attn_masks = batch['attn_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        images = [img.to(device) for img in batch['imgs']]\n",
    "\n",
    "        gold_label = batch['rating'].to(device)\n",
    "\n",
    "        outputs = language_and_vision_model(input_ids, attn_masks, token_type_ids, images)\n",
    "\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        gold_labels.extend(gold_label.cpu().numpy())\n",
    "\n",
    "        loss = loss_fn(outputs, gold_label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "average_loss = total_loss / len(dataloader)\n",
    "print(f'Average Loss: {average_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(gold_labels, predictions, squared=False)\n",
    "mae = mean_absolute_error(gold_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE: {rmse.item():.4f}\")\n",
    "print(f\"MAE: {mae.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
