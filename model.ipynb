{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusfilvi@GU.GU.SE/.conda/envs/AICS/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "\n",
    "from transformers import BertTokenizer, DistilBertModel, VisualBertModel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast, os\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, classification_report\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "batch_size = 4\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_values(ratings, tags):\n",
    "    for i, tag in enumerate(tags):\n",
    "        if tag == 'concrete':\n",
    "            ratings[i] = 0\n",
    "        elif tag == 'middle':\n",
    "            ratings[i] = 1\n",
    "        else:\n",
    "            ratings[i] = 2\n",
    "    return ratings\n",
    "\n",
    "class Multimodal_Dataset(Dataset):\n",
    "    def __init__(self, words_file, image_file, tokenizer):\n",
    "        self.words_file = words_file\n",
    "        self.images = image_file\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.data = pd.read_csv(words_file)\n",
    "        self.words = self.data['word'].to_list()\n",
    "        self.encodings = self.tokenizer([word for word in self.words], add_special_tokens=True, padding='longest', return_tensors='pt')\n",
    "\n",
    "        self.photos = self.data['photos'].apply(ast.literal_eval)\n",
    "        self.labels = self.data['tag'].to_list()\n",
    "        ratings = self.data['rating'].to_list()\n",
    "        self.ratings = map_values(ratings, self.labels)\n",
    "\n",
    "        transform_list = [\n",
    "            transforms.Grayscale(1),\n",
    "            transforms.Resize((32, 168)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ]\n",
    "        self.transform = transforms.Compose(transform_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images = self.photos[idx]\n",
    "        imgs = []\n",
    "        for image in images:\n",
    "          img_path = os.path.join('images/', image)\n",
    "          img = Image.open(img_path).convert('RGB')\n",
    "          img = self.transform(img)\n",
    "          imgs.append(img)\n",
    "\n",
    "        # #padding list of images, without this the dataloader results in errors\n",
    "        while len(imgs) < 12:\n",
    "            imgs.append(torch.zeros_like(imgs[0]))\n",
    "\n",
    "        #imgs = torch.stack(imgs)\n",
    "        #print(f\"Word: {self.words[idx]}, Number of images: {len(images)}\")\n",
    "\n",
    "        item = {'word': self.words[idx], 'input_ids': self.encodings['input_ids'][idx], 'attn_mask': self.encodings['attention_mask'][idx], 'token_type_ids': self.encodings['token_type_ids'],'imgs': imgs, 'rating': self.ratings[idx],'label': self.labels[idx]}\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'rack',\n",
       " 'input_ids': tensor([  101, 14513,   102,     0,     0,     0,     0]),\n",
       " 'attn_mask': tensor([1, 1, 1, 0, 0, 0, 0]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'imgs': [tensor([[[-0.3647, -0.3412, -0.3333,  ..., -0.2078, -0.1843, -0.2000],\n",
       "           [-0.3255, -0.3098, -0.3020,  ..., -0.1373, -0.1216, -0.1529],\n",
       "           [-0.2941, -0.2784, -0.2549,  ..., -0.1294, -0.0510, -0.0431],\n",
       "           ...,\n",
       "           [-0.7412, -0.7333, -0.7098,  ..., -0.5059, -0.5059, -0.5373],\n",
       "           [-0.7098, -0.7020, -0.6706,  ..., -0.5294, -0.4745, -0.4667],\n",
       "           [-0.6235, -0.6549, -0.6549,  ..., -0.5373, -0.5137, -0.5843]]]),\n",
       "  tensor([[[-0.8275, -0.8588, -0.9059,  ..., -0.4431, -0.3961, -0.4353],\n",
       "           [-0.7569, -0.7961, -0.8353,  ..., -0.1451, -0.3020, -0.4196],\n",
       "           [-0.5137, -0.6000, -0.6549,  ..., -0.0667, -0.2471, -0.2784],\n",
       "           ...,\n",
       "           [-0.3647, -0.3255, -0.3647,  ...,  0.4118,  0.3961,  0.1373],\n",
       "           [-0.5137, -0.5137, -0.5529,  ..., -0.1608, -0.0824, -0.0902],\n",
       "           [-0.2784, -0.3961, -0.3961,  ..., -0.5294, -0.5765, -0.6000]]]),\n",
       "  tensor([[[ 0.4510,  0.4510,  0.4588,  ..., -0.6941, -0.6549, -0.6549],\n",
       "           [ 0.4824,  0.4824,  0.4902,  ..., -0.7412, -0.6784, -0.6314],\n",
       "           [ 0.5294,  0.5294,  0.5294,  ..., -0.7569, -0.7176, -0.6471],\n",
       "           ...,\n",
       "           [-0.1059, -0.1137, -0.1451,  ..., -0.0510, -0.0824, -0.0667],\n",
       "           [-0.0745, -0.0745, -0.1294,  ..., -0.3882, -0.3569, -0.2157],\n",
       "           [-0.2000, -0.2000, -0.2471,  ..., -0.6627, -0.6627, -0.6235]]]),\n",
       "  tensor([[[0.4275, 0.4353, 0.4353,  ..., 0.4431, 0.4431, 0.4431],\n",
       "           [0.4275, 0.4353, 0.4353,  ..., 0.4431, 0.4431, 0.4431],\n",
       "           [0.4275, 0.4353, 0.4353,  ..., 0.4431, 0.4431, 0.4431],\n",
       "           ...,\n",
       "           [0.4196, 0.4196, 0.4196,  ..., 0.4353, 0.4353, 0.4353],\n",
       "           [0.4196, 0.4275, 0.4275,  ..., 0.4353, 0.4275, 0.4275],\n",
       "           [0.4196, 0.4275, 0.4275,  ..., 0.4275, 0.4275, 0.4275]]]),\n",
       "  tensor([[[-1.0000, -1.0000, -1.0000,  ..., -0.2706, -0.2784, -0.2157],\n",
       "           [-0.9765, -0.9922, -1.0000,  ..., -0.2706, -0.3490, -0.3020],\n",
       "           [-0.8353, -0.8902, -0.9373,  ..., -0.1608, -0.2314, -0.2392],\n",
       "           ...,\n",
       "           [ 0.0745,  0.1137,  0.1451,  ...,  0.2157,  0.2078,  0.1137],\n",
       "           [ 0.1373,  0.1451,  0.0980,  ...,  0.1608,  0.1529,  0.1373],\n",
       "           [ 0.0902,  0.0196, -0.0667,  ...,  0.1922,  0.0980,  0.0902]]]),\n",
       "  tensor([[[ 0.0275, -0.1137, -0.4275,  ...,  0.9843,  0.9294,  0.8510],\n",
       "           [ 0.3569,  0.3098, -0.2471,  ...,  0.9451,  0.9765,  0.9216],\n",
       "           [ 0.0824,  0.0980,  0.1294,  ...,  0.6157,  0.7333,  0.7333],\n",
       "           ...,\n",
       "           [-0.6863, -0.6471, -0.7333,  ..., -0.3490, -0.4745, -0.6235],\n",
       "           [-0.7176, -0.7176, -0.7098,  ..., -0.5451, -0.5843, -0.5373],\n",
       "           [-0.5922, -0.6157, -0.4902,  ..., -0.7804, -0.7412, -0.6549]]]),\n",
       "  tensor([[[-0.8902, -0.6549, -0.5843,  ..., -0.7804, -0.7804, -0.7882],\n",
       "           [-0.8980, -0.2863, -0.1608,  ..., -0.7569, -0.6471, -0.4353],\n",
       "           [-0.7961, -0.0431,  0.2000,  ..., -0.4667, -0.1059,  0.1294],\n",
       "           ...,\n",
       "           [ 0.1529, -0.1216, -0.3725,  ..., -0.2235, -0.1608,  0.0039],\n",
       "           [ 0.5608, -0.3490, -0.8196,  ..., -0.4510, -0.3098, -0.0275],\n",
       "           [-0.1137, -0.6000, -0.8510,  ..., -0.4902, -0.3490, -0.0431]]]),\n",
       "  tensor([[[ 0.9765,  0.9843,  0.9843,  ...,  0.9608,  0.9529,  0.9451],\n",
       "           [ 0.9843,  0.9765,  0.9765,  ...,  0.9608,  0.9529,  0.9451],\n",
       "           [ 0.9843,  0.9765,  0.9765,  ...,  0.9529,  0.9529,  0.9451],\n",
       "           ...,\n",
       "           [-0.3725, -0.3961, -0.4588,  ..., -0.4588, -0.4745, -0.4745],\n",
       "           [-0.4039, -0.4431, -0.4510,  ..., -0.4588, -0.5451, -0.4980],\n",
       "           [-0.4118, -0.4431, -0.4588,  ..., -0.4353, -0.5137, -0.4745]]]),\n",
       "  tensor([[[ 0.1765,  0.1765,  0.2000,  ...,  0.1765,  0.1608,  0.1451],\n",
       "           [ 0.2314,  0.2314,  0.2471,  ...,  0.2235,  0.2078,  0.2000],\n",
       "           [ 0.2706,  0.2706,  0.2941,  ...,  0.2627,  0.2471,  0.2471],\n",
       "           ...,\n",
       "           [-0.0353, -0.0039,  0.0824,  ..., -0.6078, -0.6078, -0.6078],\n",
       "           [-0.6784, -0.6863, -0.4745,  ..., -0.8039, -0.8039, -0.8118],\n",
       "           [-0.7333, -0.7255, -0.6078,  ..., -0.8196, -0.8196, -0.8275]]]),\n",
       "  tensor([[[-0.4118, -0.3961, -0.3882,  ..., -0.5608, -0.4745, -0.5059],\n",
       "           [-0.3804, -0.3647, -0.3569,  ..., -0.4824, -0.4118, -0.4431],\n",
       "           [-0.3412, -0.3255, -0.3176,  ..., -0.3882, -0.3490, -0.3804],\n",
       "           ...,\n",
       "           [-0.3333, -0.3255, -0.3255,  ...,  0.2314,  0.2000,  0.1373],\n",
       "           [-0.3804, -0.3725, -0.3647,  ..., -0.0353, -0.0510, -0.0275],\n",
       "           [-0.4275, -0.4118, -0.4039,  ...,  0.6157,  0.6000,  0.5529]]]),\n",
       "  tensor([[[ 0.1686,  0.2392,  0.3176,  ..., -0.8118, -0.8118, -0.7882],\n",
       "           [ 0.5608,  0.6314,  0.6941,  ..., -0.8902, -0.8824, -0.8824],\n",
       "           [ 0.5608,  0.6392,  0.7020,  ..., -0.8745, -0.8667, -0.8667],\n",
       "           ...,\n",
       "           [-0.7412, -0.7333, -0.7176,  ..., -0.3020, -0.3882, -0.4431],\n",
       "           [-0.7569, -0.7490, -0.7412,  ..., -0.4667, -0.4902, -0.4980],\n",
       "           [-0.6784, -0.7255, -0.7412,  ..., -0.5059, -0.5373, -0.5922]]]),\n",
       "  tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]])],\n",
       " 'rating': 0,\n",
       " 'label': 'concrete'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Multimodal_Dataset('merged_data.csv', 'images', tokenizer=tokenizer)\n",
    "data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': ['noncontributing', 'summertime', 'essayist', 'unusualness'], 'input_ids': tensor([[  101,  2512,  8663, 18886,  8569,  3436,   102],\n",
      "        [  101,  2621,  7292,   102,     0,     0,     0],\n",
      "        [  101,  9491,  2923,   102,     0,     0,     0],\n",
      "        [  101,  5866,  2791,   102,     0,     0,     0]]), 'attn_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]]), 'imgs': [tensor([[[[-0.8196, -0.8118, -0.7804,  ..., -0.9216, -0.9373, -0.9216],\n",
      "          [-0.8275, -0.8118, -0.7882,  ..., -0.9216, -0.9216, -0.9137],\n",
      "          [-0.8196, -0.7961, -0.7725,  ..., -0.9216, -0.9294, -0.9294],\n",
      "          ...,\n",
      "          [-0.9059, -0.9059, -0.9137,  ..., -0.9373, -0.9373, -0.9373],\n",
      "          [-0.9059, -0.9059, -0.9059,  ..., -0.9373, -0.9373, -0.9373],\n",
      "          [-0.8980, -0.9059, -0.9059,  ..., -0.9451, -0.9451, -0.9451]]],\n",
      "\n",
      "\n",
      "        [[[-0.5686, -0.5294, -0.5059,  ..., -0.5216, -0.5137, -0.5294],\n",
      "          [-0.6078, -0.5765, -0.5608,  ..., -0.5059, -0.5451, -0.5922],\n",
      "          [-0.5373, -0.5686, -0.5765,  ..., -0.5529, -0.5294, -0.5451],\n",
      "          ...,\n",
      "          [-0.0196, -0.2863, -0.5216,  ..., -0.3804, -0.4039, -0.5529],\n",
      "          [-0.4353, -0.4980, -0.5529,  ..., -0.3804, -0.3725, -0.4353],\n",
      "          [-0.6627, -0.7098, -0.6314,  ..., -0.6000, -0.5843, -0.4980]]],\n",
      "\n",
      "\n",
      "        [[[-0.0118, -0.0275, -0.0353,  ..., -0.1608, -0.1294, -0.1137],\n",
      "          [-0.0431, -0.0667, -0.0510,  ...,  0.5843,  0.5529,  0.5059],\n",
      "          [-0.4353, -0.4431, -0.4431,  ..., -0.2941, -0.3412, -0.3804],\n",
      "          ...,\n",
      "          [-0.2471, -0.2627, -0.2235,  ..., -0.4824, -0.4824, -0.5059],\n",
      "          [-0.2314, -0.1686, -0.2157,  ..., -0.3255, -0.3255, -0.3490],\n",
      "          [-0.3020, -0.2549, -0.2627,  ..., -0.3098, -0.3255, -0.3412]]],\n",
      "\n",
      "\n",
      "        [[[-0.8980, -0.9137, -0.8824,  ..., -0.9137, -0.9059, -0.9137],\n",
      "          [-0.8902, -0.9059, -0.8745,  ..., -0.9137, -0.9137, -0.9137],\n",
      "          [-0.8824, -0.9059, -0.8588,  ..., -0.9137, -0.9137, -0.9059],\n",
      "          ...,\n",
      "          [-0.8824, -0.8824, -0.8745,  ..., -0.5843, -0.7098, -0.7098],\n",
      "          [-0.8275, -0.8588, -0.8824,  ..., -0.6314, -0.6941, -0.7176],\n",
      "          [-0.7020, -0.6706, -0.7725,  ..., -0.7255, -0.7490, -0.7725]]]]), tensor([[[[-0.9294, -0.9294, -0.9216,  ...,  0.0980,  0.0431,  0.0039],\n",
      "          [-0.9059, -0.8980, -0.8980,  ..., -0.6784, -0.6941, -0.7098],\n",
      "          [-0.8824, -0.8745, -0.8745,  ..., -0.8118, -0.8196, -0.8196],\n",
      "          ...,\n",
      "          [-0.9608, -0.9529, -0.9529,  ..., -0.8745, -0.8745, -0.8745],\n",
      "          [-0.9608, -0.9529, -0.9529,  ..., -0.8588, -0.8588, -0.8667],\n",
      "          [-0.9608, -0.9608, -0.9608,  ..., -0.8588, -0.8510, -0.8667]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6314,  0.6471,  0.6471,  ...,  0.8588,  0.8588,  0.8588],\n",
      "          [ 0.6627,  0.6706,  0.6784,  ...,  0.8588,  0.8588,  0.8588],\n",
      "          [ 0.6941,  0.6941,  0.7020,  ...,  0.6706,  0.7176,  0.8275],\n",
      "          ...,\n",
      "          [ 0.8902,  0.8902,  0.9059,  ..., -0.6392, -0.6549, -0.6549],\n",
      "          [ 0.8902,  0.8824,  0.8980,  ..., -0.7020, -0.7412, -0.7412],\n",
      "          [ 0.8902,  0.8824,  0.8980,  ..., -0.6549, -0.6941, -0.7176]]],\n",
      "\n",
      "\n",
      "        [[[-0.3882, -0.3647, -0.4353,  ..., -0.8353, -0.8902, -0.9373],\n",
      "          [-0.4196, -0.4588, -0.5922,  ..., -0.9059, -0.9451, -0.9373],\n",
      "          [-0.6627, -0.6863, -0.7176,  ..., -0.8824, -0.8745, -0.9529],\n",
      "          ...,\n",
      "          [-0.8980, -0.8980, -0.8824,  ..., -0.9843, -0.9686, -0.9216],\n",
      "          [-0.9373, -0.9451, -0.9373,  ..., -0.9765, -0.9451, -0.9373],\n",
      "          [-0.9373, -0.9451, -0.9529,  ..., -0.9451, -0.9451, -0.9686]]],\n",
      "\n",
      "\n",
      "        [[[-0.5608, -0.5529, -0.5373,  ..., -0.5843, -0.5922, -0.6000],\n",
      "          [-0.5294, -0.5294, -0.5216,  ..., -0.6941, -0.7020, -0.7098],\n",
      "          [-0.5373, -0.5294, -0.5373,  ..., -0.7333, -0.7412, -0.7569],\n",
      "          ...,\n",
      "          [-0.4667, -0.4902, -0.5059,  ..., -0.9608, -0.9765, -0.9765],\n",
      "          [-0.4431, -0.4118, -0.3569,  ..., -0.9451, -0.9529, -0.9765],\n",
      "          [-0.7804, -0.7961, -0.8039,  ..., -0.6784, -0.6863, -0.7569]]]]), tensor([[[[-0.7569, -0.7412, -0.7333,  ..., -0.7961, -0.7961, -0.7961],\n",
      "          [-0.7490, -0.7412, -0.7412,  ..., -0.7961, -0.7961, -0.7961],\n",
      "          [-0.6549, -0.6471, -0.6471,  ..., -0.7804, -0.7882, -0.7882],\n",
      "          ...,\n",
      "          [-0.4902, -0.5294, -0.4980,  ..., -0.8667, -0.8431, -0.8118],\n",
      "          [-0.4431, -0.5216, -0.5294,  ..., -0.9059, -0.8980, -0.9059],\n",
      "          [-0.5843, -0.6078, -0.6078,  ..., -0.8902, -0.8980, -0.8980]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1373, -0.1373, -0.3882,  ...,  0.2314,  0.2235,  0.2078],\n",
      "          [ 0.2392, -0.0510, -0.3490,  ...,  0.2235,  0.2078,  0.2078],\n",
      "          [-0.1529, -0.2157, -0.4353,  ...,  0.2078,  0.2000,  0.2000],\n",
      "          ...,\n",
      "          [ 0.5216,  0.1843,  0.1608,  ...,  0.3490,  0.3569,  0.3569],\n",
      "          [ 0.7961,  0.2784,  0.1294,  ...,  0.3412,  0.2706,  0.2235],\n",
      "          [ 0.7725,  0.4902, -0.0039,  ...,  0.2549,  0.2078,  0.1843]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4980,  0.5373,  0.5922,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [-0.5294, -0.5137, -0.4980,  ...,  0.9843,  0.9843,  0.9922],\n",
      "          [-0.5843, -0.5922, -0.6000,  ...,  0.9608,  0.9608,  0.9608],\n",
      "          ...,\n",
      "          [-0.4275, -0.4431, -0.4510,  ..., -0.7804, -0.7961, -0.7882],\n",
      "          [-0.3412, -0.3490, -0.3647,  ..., -0.7333, -0.7412, -0.7490],\n",
      "          [-0.3490, -0.3490, -0.3569,  ..., -0.6549, -0.6627, -0.6784]]]]), tensor([[[[ 0.5608,  0.5686,  0.5843,  ...,  0.5922,  0.5765,  0.5608],\n",
      "          [ 0.6157,  0.6314,  0.6392,  ...,  0.6471,  0.6314,  0.6235],\n",
      "          [ 0.6706,  0.6863,  0.6941,  ...,  0.7020,  0.6863,  0.6784],\n",
      "          ...,\n",
      "          [ 0.7098,  0.7255,  0.7333,  ...,  0.7098,  0.6941,  0.6863],\n",
      "          [ 0.6706,  0.6863,  0.6941,  ...,  0.6549,  0.6471,  0.6392],\n",
      "          [ 0.6314,  0.6392,  0.6471,  ...,  0.6078,  0.5922,  0.5843]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0196,  0.0353,  0.0510,  ...,  0.3490,  0.3569,  0.3569],\n",
      "          [ 0.1059,  0.0980,  0.0902,  ...,  0.3412,  0.3490,  0.3647],\n",
      "          [ 0.1059,  0.1059,  0.0980,  ...,  0.3490,  0.3569,  0.3725],\n",
      "          ...,\n",
      "          [-0.4980, -0.3961, -0.2941,  ..., -0.0275, -0.0118, -0.0039],\n",
      "          [-0.5137, -0.4588, -0.3569,  ..., -0.0745, -0.0588, -0.0510],\n",
      "          [-0.5608, -0.4824, -0.3804,  ..., -0.0980, -0.0902, -0.0902]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4039,  0.4118,  0.4353,  ...,  0.8431,  0.8431,  0.8588],\n",
      "          [ 0.9529,  0.9529,  0.9529,  ...,  0.8667,  0.8745,  0.8824],\n",
      "          [ 0.9686,  0.9765,  0.9686,  ...,  0.8745,  0.8980,  0.9059],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.7020, -0.7020, -0.7098],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.7333, -0.7255, -0.7412],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -0.6627, -0.6784, -0.7176]]],\n",
      "\n",
      "\n",
      "        [[[-0.7020, -0.6863, -0.6784,  ...,  0.4275,  0.4824,  0.5216],\n",
      "          [-0.7098, -0.6941, -0.6627,  ...,  0.4431,  0.4745,  0.5608],\n",
      "          [-0.6941, -0.6706, -0.6471,  ...,  0.4980,  0.5451,  0.5686],\n",
      "          ...,\n",
      "          [-0.7255, -0.6863, -0.6314,  ...,  0.0824,  0.1216,  0.0196],\n",
      "          [-0.7255, -0.6863, -0.6314,  ...,  0.0510,  0.0353, -0.0510],\n",
      "          [-0.7333, -0.7020, -0.6235,  ...,  0.0118, -0.0275, -0.1686]]]]), tensor([[[[ 0.0196,  0.0196,  0.0275,  ..., -0.0824, -0.0510, -0.0196],\n",
      "          [ 0.5529,  0.5451,  0.5373,  ...,  0.0980,  0.1059,  0.1059],\n",
      "          [ 0.7412,  0.7412,  0.7412,  ...,  0.4745,  0.4902,  0.4667],\n",
      "          ...,\n",
      "          [-0.1294, -0.1529, -0.1686,  ..., -0.3255, -0.2941, -0.2863],\n",
      "          [-0.2078, -0.1843, -0.2235,  ..., -0.0824, -0.0588, -0.1216],\n",
      "          [-0.2000, -0.2078, -0.2706,  ..., -0.1059, -0.1216, -0.1451]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7412,  0.7804,  0.7961,  ..., -0.7647, -0.7569, -0.7490],\n",
      "          [ 0.3176,  0.3647,  0.4275,  ..., -0.7647, -0.7569, -0.7569],\n",
      "          [-0.1922, -0.1922, -0.1765,  ..., -0.7647, -0.7647, -0.7569],\n",
      "          ...,\n",
      "          [-0.0588, -0.0588, -0.0588,  ..., -0.3098, -0.3098, -0.3098],\n",
      "          [-0.0431, -0.0353, -0.0431,  ..., -0.3176, -0.3176, -0.3098],\n",
      "          [-0.0275, -0.0275, -0.0431,  ..., -0.3255, -0.3176, -0.3176]]],\n",
      "\n",
      "\n",
      "        [[[-0.2000, -0.2078, -0.4039,  ...,  0.1686,  0.5294,  0.6000],\n",
      "          [-0.1608, -0.1451, -0.2471,  ...,  0.2706,  0.5843,  0.6471],\n",
      "          [-0.1137, -0.0902, -0.1137,  ...,  0.2627,  0.6078,  0.6706],\n",
      "          ...,\n",
      "          [-0.6549, -0.6392, -0.6078,  ..., -0.4902, -0.0353,  0.3569],\n",
      "          [-0.7333, -0.7490, -0.7569,  ..., -0.5216, -0.0902,  0.3176],\n",
      "          [-0.9059, -0.9137, -0.9216,  ..., -0.5294, -0.0588,  0.3098]]],\n",
      "\n",
      "\n",
      "        [[[-0.3333, -0.3098, -0.2941,  ..., -0.1451, -0.1137, -0.0824],\n",
      "          [-0.3412, -0.3098, -0.2863,  ..., -0.1765, -0.1451, -0.1059],\n",
      "          [-0.3333, -0.3255, -0.3098,  ..., -0.2549, -0.2157, -0.1686],\n",
      "          ...,\n",
      "          [-0.6706, -0.6706, -0.6706,  ..., -0.7961, -0.7961, -0.7961],\n",
      "          [-0.7020, -0.7020, -0.7020,  ..., -0.8196, -0.8118, -0.8118],\n",
      "          [-0.7255, -0.7255, -0.7255,  ..., -0.8196, -0.8196, -0.8196]]]]), tensor([[[[ 0.3569,  0.3333,  0.2627,  ..., -0.0353, -0.0196, -0.0275],\n",
      "          [ 0.3961,  0.3882,  0.3804,  ...,  0.4039,  0.4275,  0.4196],\n",
      "          [ 0.4353,  0.4275,  0.4118,  ...,  0.4039,  0.3961,  0.4039],\n",
      "          ...,\n",
      "          [ 0.1843,  0.2157,  0.2078,  ...,  0.0745,  0.0902,  0.0588],\n",
      "          [ 0.2471,  0.2549,  0.2392,  ...,  0.0980,  0.1137,  0.0745],\n",
      "          [ 0.2549,  0.3020,  0.2706,  ...,  0.1373,  0.1059,  0.0902]]],\n",
      "\n",
      "\n",
      "        [[[-0.4353, -0.4353, -0.4353,  ..., -0.3333, -0.4196, -0.4902],\n",
      "          [-0.4118, -0.4196, -0.4353,  ...,  0.4353,  0.3098,  0.1765],\n",
      "          [-0.4667, -0.4980, -0.5294,  ...,  0.8353,  0.8196,  0.7882],\n",
      "          ...,\n",
      "          [ 0.2549,  0.2784,  0.2941,  ...,  0.1294,  0.2078,  0.1608],\n",
      "          [ 0.3098,  0.3490,  0.3020,  ...,  0.0980,  0.1294,  0.1373],\n",
      "          [ 0.2471,  0.2471,  0.1765,  ...,  0.1608,  0.1216,  0.0118]]],\n",
      "\n",
      "\n",
      "        [[[-0.8588, -0.8431, -0.8118,  ..., -0.7020, -0.6863, -0.6706],\n",
      "          [-0.7961, -0.7882, -0.7882,  ..., -0.6941, -0.6784, -0.6549],\n",
      "          [-0.7176, -0.7176, -0.7176,  ..., -0.6941, -0.6627, -0.6314],\n",
      "          ...,\n",
      "          [-0.3098, -0.3098, -0.3020,  ..., -0.6392, -0.6471, -0.6471],\n",
      "          [-0.4510, -0.4431, -0.4431,  ..., -0.6157, -0.6235, -0.6235],\n",
      "          [-0.5843, -0.5843, -0.5765,  ..., -0.6314, -0.6471, -0.6471]]],\n",
      "\n",
      "\n",
      "        [[[-0.6157, -0.6157, -0.6157,  ..., -0.5922, -0.5922, -0.6000],\n",
      "          [-0.6157, -0.6157, -0.6157,  ..., -0.6000, -0.6000, -0.6000],\n",
      "          [-0.6078, -0.6157, -0.6157,  ..., -0.6000, -0.6000, -0.6000],\n",
      "          ...,\n",
      "          [-0.6235, -0.6235, -0.6157,  ..., -0.6235, -0.6235, -0.6235],\n",
      "          [-0.6235, -0.6235, -0.6157,  ..., -0.6235, -0.6235, -0.6314],\n",
      "          [-0.6157, -0.6235, -0.6157,  ..., -0.6157, -0.6235, -0.6235]]]]), tensor([[[[ 0.3333, -0.0588, -0.0275,  ..., -0.4039, -0.3333,  0.0510],\n",
      "          [ 0.3098, -0.0824, -0.0745,  ..., -0.3176, -0.3176,  0.1922],\n",
      "          [ 0.3255, -0.0667, -0.0745,  ..., -0.2392, -0.2549,  0.2314],\n",
      "          ...,\n",
      "          [ 0.4275,  0.0980,  0.0902,  ..., -0.4196, -0.4431,  0.0745],\n",
      "          [ 0.4118,  0.0510,  0.1216,  ..., -0.4667, -0.5373, -0.0118],\n",
      "          [ 0.4353,  0.0667,  0.1216,  ..., -0.3882, -0.5059,  0.0275]]],\n",
      "\n",
      "\n",
      "        [[[-0.3882, -0.3647, -0.3882,  ...,  0.8588,  0.7961,  0.6863],\n",
      "          [-0.0275, -0.0510, -0.0667,  ...,  0.9608,  0.8980,  0.7804],\n",
      "          [ 0.0902,  0.0667,  0.0667,  ...,  0.8745,  0.7804,  0.6000],\n",
      "          ...,\n",
      "          [ 0.5922,  0.5922,  0.5922,  ..., -0.0275, -0.0431, -0.0588],\n",
      "          [ 0.5529,  0.5608,  0.5686,  ...,  0.1686,  0.1608,  0.1451],\n",
      "          [ 0.4667,  0.4745,  0.4902,  ...,  0.1843,  0.1686,  0.1608]]],\n",
      "\n",
      "\n",
      "        [[[-0.6627, -0.6706, -0.6706,  ..., -0.6549, -0.6549, -0.6549],\n",
      "          [-0.6549, -0.6627, -0.6549,  ..., -0.6235, -0.6157, -0.6078],\n",
      "          [-0.6471, -0.6471, -0.6392,  ..., -0.0431, -0.0118,  0.0196],\n",
      "          ...,\n",
      "          [-0.6392, -0.6392, -0.6314,  ...,  0.2549,  0.2549,  0.2471],\n",
      "          [-0.6314, -0.6314, -0.6235,  ...,  0.2000,  0.2157,  0.2235],\n",
      "          [-0.6471, -0.6314, -0.6314,  ...,  0.0275,  0.0667,  0.0824]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -0.9922,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -0.9765,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -0.9922, -0.9373,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -0.9843, -0.8667,  ..., -0.9922, -1.0000, -1.0000],\n",
      "          [-1.0000, -0.9843, -0.8667,  ..., -0.9922, -1.0000, -1.0000],\n",
      "          [-1.0000, -0.9922, -0.9373,  ..., -0.9922, -1.0000, -1.0000]]]]), tensor([[[[-0.5294, -0.4902, -0.5765,  ..., -0.2627, -0.2627, -0.2706],\n",
      "          [-0.5529, -0.5686, -0.5529,  ..., -0.2863, -0.2863, -0.2941],\n",
      "          [-0.6627, -0.6784, -0.6314,  ..., -0.4275, -0.4275, -0.4588],\n",
      "          ...,\n",
      "          [-0.7176, -0.6078, -0.7569,  ..., -0.7882, -0.8039, -0.8431],\n",
      "          [-0.6392, -0.6706, -0.6941,  ..., -0.7569, -0.7569, -0.7804],\n",
      "          [-0.6157, -0.6078, -0.6000,  ..., -0.7333, -0.7725, -0.8039]]],\n",
      "\n",
      "\n",
      "        [[[-0.8745, -0.8745, -0.8824,  ..., -0.8667, -0.8667, -0.8667],\n",
      "          [-0.8667, -0.8745, -0.8667,  ..., -0.8510, -0.8510, -0.8588],\n",
      "          [-0.8745, -0.8667, -0.8667,  ..., -0.8588, -0.8588, -0.8510],\n",
      "          ...,\n",
      "          [-0.8980, -0.8980, -0.8902,  ..., -0.9137, -0.9137, -0.9216],\n",
      "          [-0.8980, -0.8980, -0.8980,  ..., -0.9137, -0.9137, -0.9137],\n",
      "          [-0.8980, -0.9059, -0.9137,  ..., -0.9059, -0.9059, -0.9137]]],\n",
      "\n",
      "\n",
      "        [[[-0.4824, -0.4510, -0.4431,  ..., -0.4431, -0.4510, -0.4980],\n",
      "          [-0.4431, -0.3961, -0.3804,  ..., -0.3804, -0.3961, -0.4431],\n",
      "          [-0.3961, -0.3412, -0.3255,  ..., -0.3255, -0.3412, -0.3961],\n",
      "          ...,\n",
      "          [ 0.3020,  0.3804,  0.3569,  ...,  0.2471,  0.2549,  0.1608],\n",
      "          [ 0.2157,  0.2863,  0.2549,  ...,  0.1922,  0.2314,  0.1451],\n",
      "          [ 0.0824,  0.1608,  0.1451,  ...,  0.0824,  0.1608,  0.0902]]],\n",
      "\n",
      "\n",
      "        [[[-0.6627, -0.6157, -0.6078,  ..., -0.8353, -0.8980, -0.9373],\n",
      "          [-0.4196, -0.4431, -0.4431,  ..., -0.2706, -0.4275, -0.5765],\n",
      "          [-0.5059, -0.4980, -0.5216,  ..., -0.1373, -0.1843, -0.2863],\n",
      "          ...,\n",
      "          [-0.7176, -0.7020, -0.6314,  ..., -0.4275, -0.3412, -0.1137],\n",
      "          [-0.4431, -0.5059, -0.5922,  ..., -0.4824, -0.4353, -0.4353],\n",
      "          [-0.5608, -0.6392, -0.6784,  ..., -0.5373, -0.4824, -0.4667]]]]), tensor([[[[-0.1059, -0.1059, -0.0980,  ..., -0.8118, -0.8588, -0.8824],\n",
      "          [-0.2000, -0.2000, -0.1922,  ..., -0.7020, -0.7333, -0.7569],\n",
      "          [-0.3882, -0.3176, -0.2392,  ..., -0.6471, -0.6706, -0.7020],\n",
      "          ...,\n",
      "          [-0.1294, -0.1294, -0.1373,  ..., -0.3725, -0.3725, -0.3725],\n",
      "          [-0.1216, -0.1216, -0.1294,  ..., -0.4039, -0.3961, -0.3882],\n",
      "          [-0.1373, -0.1373, -0.1373,  ..., -0.4039, -0.4118, -0.4039]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6392,  0.6471,  0.6471,  ...,  0.6314,  0.6314,  0.6314],\n",
      "          [ 0.6549,  0.6549,  0.6549,  ...,  0.6392,  0.6392,  0.6314],\n",
      "          [ 0.6549,  0.6627,  0.6706,  ...,  0.6471,  0.6471,  0.6471],\n",
      "          ...,\n",
      "          [ 0.1765,  0.2549,  0.4353,  ..., -0.1843, -0.1608, -0.1529],\n",
      "          [ 0.0510,  0.0431,  0.0745,  ...,  0.0039,  0.0039, -0.0118],\n",
      "          [ 0.2078,  0.1529,  0.0980,  ..., -0.0745, -0.0510, -0.0824]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0118,  0.4196,  0.6941,  ..., -0.4039, -0.4824, -0.7882],\n",
      "          [-0.0431,  0.3176,  0.6235,  ..., -0.2941, -0.4510, -0.7961],\n",
      "          [-0.0667,  0.2784,  0.5922,  ..., -0.2392, -0.5059, -0.8196],\n",
      "          ...,\n",
      "          [-0.3569, -0.2706, -0.1137,  ..., -0.7333, -0.7176, -0.6784],\n",
      "          [-0.5529, -0.5373, -0.4824,  ..., -0.6784, -0.6471, -0.5843],\n",
      "          [-0.5059, -0.4824, -0.4667,  ..., -0.5686, -0.5216, -0.4353]]],\n",
      "\n",
      "\n",
      "        [[[-0.3020, -0.3098, -0.3020,  ...,  0.1451,  0.0902,  0.0431],\n",
      "          [-0.5529, -0.5922, -0.6157,  ...,  0.2000,  0.2000,  0.1843],\n",
      "          [-0.4980, -0.5686, -0.6078,  ...,  0.1686,  0.1922,  0.2000],\n",
      "          ...,\n",
      "          [-0.4275, -0.4196, -0.4588,  ..., -0.3098, -0.3098, -0.3098],\n",
      "          [-0.4118, -0.3882, -0.4353,  ..., -0.3647, -0.3569, -0.3725],\n",
      "          [-0.7020, -0.6863, -0.6471,  ..., -0.3961, -0.3725, -0.3804]]]]), tensor([[[[ 0.1765,  0.0824, -0.0510,  ..., -0.8275, -0.8275, -0.8275],\n",
      "          [ 0.4902,  0.4588,  0.3804,  ..., -0.8745, -0.8667, -0.8588],\n",
      "          [ 0.5451,  0.5294,  0.5137,  ..., -0.6078, -0.6078, -0.6078],\n",
      "          ...,\n",
      "          [-0.4118, -0.4118, -0.4118,  ..., -0.7176, -0.7333, -0.7176],\n",
      "          [ 0.0039,  0.0196,  0.0118,  ..., -0.5843, -0.5922, -0.5843],\n",
      "          [ 0.2000,  0.2235,  0.2392,  ..., -0.4588, -0.4667, -0.4745]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2784,  0.2784,  0.2941,  ..., -0.2706, -0.5608, -0.6471],\n",
      "          [ 0.2706,  0.2549,  0.2392,  ...,  0.2078,  0.1529,  0.1216],\n",
      "          [ 0.2941,  0.2941,  0.2941,  ...,  0.3725,  0.3725,  0.3725],\n",
      "          ...,\n",
      "          [-0.0980, -0.0667, -0.0431,  ..., -0.5137, -0.4980, -0.4902],\n",
      "          [ 0.1137,  0.1216,  0.1216,  ..., -0.5922, -0.5922, -0.5843],\n",
      "          [-0.0431, -0.0431, -0.0588,  ..., -0.5608, -0.5608, -0.5608]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.2706, -0.4980, -0.4745,  ...,  0.2078,  0.2392,  0.2392],\n",
      "          [-0.4353, -0.4118, -0.4431,  ...,  0.2314,  0.2000,  0.2549],\n",
      "          [-0.2157, -0.2706, -0.2627,  ...,  0.2157,  0.2078,  0.2157],\n",
      "          ...,\n",
      "          [-0.1294, -0.1686, -0.2000,  ..., -0.4745, -0.5922, -0.6314],\n",
      "          [-0.2706, -0.3255, -0.4118,  ..., -0.4745, -0.4824, -0.5843],\n",
      "          [-0.5843, -0.5608, -0.5373,  ...,  0.1686,  0.1686,  0.0745]]]]), tensor([[[[ 0.6549,  0.6706,  0.6784,  ...,  0.9686,  0.9686,  0.9686],\n",
      "          [ 0.6941,  0.7020,  0.7098,  ...,  0.9765,  0.9765,  0.9686],\n",
      "          [ 0.7412,  0.6706,  0.6392,  ...,  0.8980,  0.8902,  0.8902],\n",
      "          ...,\n",
      "          [-0.2627, -0.2549, -0.2392,  ...,  0.0118,  0.0039, -0.0353],\n",
      "          [-0.2078, -0.2078, -0.2078,  ..., -0.2000, -0.2000, -0.2078],\n",
      "          [-0.2784, -0.3020, -0.3098,  ..., -0.3098, -0.3412, -0.3569]]],\n",
      "\n",
      "\n",
      "        [[[-0.8902, -0.8824, -0.8824,  ...,  0.5059,  0.5843,  0.6157],\n",
      "          [-0.8824, -0.8824, -0.8824,  ...,  0.5451,  0.5922,  0.5843],\n",
      "          [-0.8824, -0.8824, -0.8902,  ...,  0.5137,  0.5216,  0.4510],\n",
      "          ...,\n",
      "          [-0.1686, -0.2235, -0.2235,  ...,  0.6000,  0.6549,  0.6078],\n",
      "          [-0.2627, -0.2627, -0.2627,  ...,  0.5922,  0.6235,  0.6000],\n",
      "          [-0.3490, -0.3255, -0.3176,  ...,  0.6471,  0.6863,  0.7020]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]]]), tensor([[[[-0.2941, -0.2784, -0.2627,  ...,  0.4196,  0.4118,  0.4118],\n",
      "          [ 0.0353,  0.0588,  0.0902,  ...,  0.3882,  0.3961,  0.4118],\n",
      "          [ 0.2235,  0.2863,  0.3255,  ...,  0.3882,  0.3804,  0.3804],\n",
      "          ...,\n",
      "          [-0.6706, -0.6941, -0.6078,  ...,  0.0353,  0.0431,  0.0510],\n",
      "          [-0.6549, -0.7020, -0.6941,  ...,  0.2157,  0.2157,  0.2157],\n",
      "          [-0.6235, -0.6784, -0.7412,  ...,  0.2000,  0.2000,  0.2078]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0039,  0.0118,  0.0196,  ...,  0.2941,  0.2941,  0.2941],\n",
      "          [ 0.0510,  0.0588,  0.0667,  ...,  0.3647,  0.3647,  0.3569],\n",
      "          [ 0.0980,  0.1059,  0.1059,  ...,  0.4510,  0.4353,  0.4196],\n",
      "          ...,\n",
      "          [-0.8353, -0.8431, -0.8196,  ..., -0.6627, -0.6784, -0.6706],\n",
      "          [-0.7882, -0.7961, -0.8275,  ..., -0.5059, -0.5529, -0.6314],\n",
      "          [-0.8118, -0.8353, -0.8431,  ..., -0.5216, -0.5451, -0.5373]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])], 'rating': tensor([2, 1, 1, 2]), 'label': ['abstract', 'middle', 'middle', 'abstract']}\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataloader):\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Textual BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEXTUAL_BERT(nn.Module):\n",
    "  def __init__(self):\n",
    "      super(TEXTUAL_BERT, self).__init__()\n",
    "      self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "      self.classifier = nn.Linear(self.bert.config.hidden_size, 3) #the number of out_features was set to 1 for a regression task\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "      outputs = self.bert(input_ids, attention_mask)\n",
    "      predictions = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
    "\n",
    "      return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 1.1360401781400045\n"
     ]
    }
   ],
   "source": [
    "model = TEXTUAL_BERT()#.to(device)\n",
    "\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "predictions = []\n",
    "gold_labels = []\n",
    "correct = 0\n",
    "samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        input_ids = torch.Tensor(batch['input_ids']).long()#.to(device)\n",
    "        attn_masks = torch.Tensor(batch['attn_mask']).long()#.to(device)\n",
    "        gold_label = batch['rating']#.to(device)\n",
    "    \n",
    "        outputs = model(input_ids, attn_masks)\n",
    "\n",
    "        gold_labels.extend(gold_label)\n",
    "\n",
    "        loss = loss_fn(outputs, gold_label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted_labels = torch.max(outputs, dim=1)\n",
    "        #print(gold_label.size(), predicted_labels.size())\n",
    "        predictions.extend(predicted_labels)\n",
    "        correct += (predicted_labels == gold_label).sum().item()\n",
    "        samples += len(gold_label)\n",
    "\n",
    "average_loss = total_loss / len(dataloader)\n",
    "print(f'Average Loss: {average_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = correct / samples\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       100\n",
      "           1       0.33      1.00      0.50       100\n",
      "           2       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.33       300\n",
      "   macro avg       0.11      0.33      0.17       300\n",
      "weighted avg       0.11      0.33      0.17       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gusfilvi@GU.GU.SE/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(gold_labels, predictions)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse = mean_squared_error(gold_labels, predictions, squared=False)\n",
    "# mae = mean_absolute_error(gold_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.1823\n",
      "MAE: 2.9540\n"
     ]
    }
   ],
   "source": [
    "# print(f\"MSE: {mse.item():.4f}\")\n",
    "# print(f\"MAE: {mae.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visual BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VISUAL_BERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VISUAL_BERT, self).__init__()\n",
    "        self.bert_model = VisualBertModel.from_pretrained(\"uclanlp/visualbert-vqa-coco-pre\")\n",
    "        self.classifier = nn.Linear(self.bert_model.config.hidden_size, 1)\n",
    "\n",
    "        self.object_detector = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    def forward(self, input_ids, attn_masks, token_type_ids, visual_embeddings):\n",
    "    \n",
    "        visual_token_type_ids = torch.ones(visual_embeddings.shape[:-1], dtype=torch.long).to(device)\n",
    "        visual_attention_mask = torch.ones(visual_embeddings.shape[:-1], dtype=torch.float).to(device)\n",
    "\n",
    "        outputs = self.bert_model(input_ids=input_ids, attention_mask=attn_masks, token_type_ids=token_type_ids, visual_embeds=visual_embeddings, visual_attention_mask=visual_attention_mask, visual_token_type_ids=visual_token_type_ids)\n",
    "        predictions = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusfilvi@GU.GU.SE/.conda/envs/AICS/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/gusfilvi@GU.GU.SE/.conda/envs/AICS/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "detector = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "def get_features(image_batch):\n",
    "    feature_extractor = nn.Sequential(*list(detector.backbone.children())[:-2])\n",
    "    visual_embeddings = []\n",
    "    for images in image_batch:\n",
    "        image_embeddings = []\n",
    "        for image in images:\n",
    "            visual_embedding = feature_extractor(image)\n",
    "            image_embeddings.append(visual_embedding)\n",
    "        visual_embeddings.append(torch.stack(image_embeddings))\n",
    "    return visual_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    images = batch['imgs']\n",
    "    print(len(get_features(images)[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 7])\n",
      "torch.Size([4, 7])\n",
      "visual embeddings 12\n",
      "tensor([[[ 0.2529,  0.2353,  0.2510,  ...,  0.3314,  0.3510,  0.3471],\n",
      "         [ 0.2784,  0.2431,  0.2078,  ...,  0.3176,  0.3216,  0.3216],\n",
      "         [ 0.2471,  0.2373,  0.2373,  ...,  0.2941,  0.2941,  0.2902],\n",
      "         ...,\n",
      "         [-0.0059, -0.0294,  0.0216,  ..., -0.2922, -0.2451, -0.2020],\n",
      "         [ 0.0078, -0.0608, -0.0549,  ..., -0.2588, -0.2216, -0.1882],\n",
      "         [-0.0706, -0.1373, -0.1216,  ..., -0.1765, -0.1882, -0.2176]],\n",
      "\n",
      "        [[ 0.0745, -0.0020, -0.0235,  ...,  0.5490,  0.5490,  0.5510],\n",
      "         [ 0.0451,  0.0235,  0.0118,  ...,  0.5392,  0.5431,  0.5431],\n",
      "         [ 0.0255,  0.0118,  0.0059,  ...,  0.5020,  0.5078,  0.5137],\n",
      "         ...,\n",
      "         [ 0.1451,  0.1510,  0.1510,  ...,  0.4373,  0.4412,  0.4255],\n",
      "         [ 0.2000,  0.2431,  0.2647,  ...,  0.4118,  0.4275,  0.3824],\n",
      "         [ 0.2176,  0.2431,  0.2725,  ...,  0.2490,  0.2235,  0.2333]],\n",
      "\n",
      "        [[ 0.0118,  0.0098,  0.0098,  ...,  0.0333,  0.0353,  0.0412],\n",
      "         [ 0.0608,  0.0588,  0.0588,  ...,  0.0255,  0.0255,  0.0333],\n",
      "         [ 0.1765,  0.1784,  0.1784,  ...,  0.0216,  0.0137,  0.0255],\n",
      "         ...,\n",
      "         [-0.2863, -0.2569, -0.2196,  ..., -0.2451, -0.2490, -0.1922],\n",
      "         [-0.2333, -0.2510, -0.2745,  ..., -0.2157, -0.2118, -0.1980],\n",
      "         [-0.3824, -0.3725, -0.3667,  ..., -0.3020, -0.2980, -0.2961]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3245, -0.3167, -0.3127,  ..., -0.2931, -0.2951, -0.2971],\n",
      "         [-0.3186, -0.3108, -0.3049,  ..., -0.2833, -0.2853, -0.2892],\n",
      "         [-0.3010, -0.3029, -0.2990,  ..., -0.2716, -0.2735, -0.2755],\n",
      "         ...,\n",
      "         [ 0.0951,  0.0971,  0.1049,  ..., -0.3951, -0.3892, -0.4108],\n",
      "         [ 0.0284,  0.0225,  0.0265,  ..., -0.4559, -0.4441, -0.4539],\n",
      "         [ 0.0206,  0.0206,  0.0225,  ..., -0.4833, -0.5010, -0.5108]],\n",
      "\n",
      "        [[ 0.1020,  0.1294,  0.1333,  ..., -0.0902, -0.1373, -0.1549],\n",
      "         [-0.0529, -0.0392, -0.0196,  ..., -0.0804, -0.1490, -0.1765],\n",
      "         [-0.1196, -0.1078, -0.0843,  ..., -0.0804, -0.1118, -0.1451],\n",
      "         ...,\n",
      "         [-0.2490, -0.2490, -0.2431,  ..., -0.2686, -0.2725, -0.2824],\n",
      "         [-0.3412, -0.3392, -0.3353,  ..., -0.2235, -0.2000, -0.2000],\n",
      "         [-0.3314, -0.3216, -0.3059,  ..., -0.2333, -0.2137, -0.2059]],\n",
      "\n",
      "        [[ 0.1304,  0.1284,  0.1284,  ...,  0.0814,  0.0814,  0.0814],\n",
      "         [ 0.1363,  0.1343,  0.1343,  ...,  0.0814,  0.0814,  0.0833],\n",
      "         [ 0.1382,  0.1382,  0.1382,  ...,  0.0833,  0.0833,  0.0853],\n",
      "         ...,\n",
      "         [-0.0735, -0.0696, -0.0716,  ..., -0.1088, -0.1108, -0.1147],\n",
      "         [-0.0814, -0.0794, -0.0794,  ..., -0.0971, -0.1010, -0.1029],\n",
      "         [-0.0735, -0.0716, -0.0735,  ..., -0.1010, -0.1010, -0.1010]]],\n",
      "       device='cuda:1')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 4 but got size 12 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m gold_label \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#print(gold_label.size())\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlanguage_and_vision_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m predictions\u001b[38;5;241m.\u001b[39mextend(outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     23\u001b[0m gold_labels\u001b[38;5;241m.\u001b[39mextend(gold_label\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/.conda/envs/AICS/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/AICS/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 20\u001b[0m, in \u001b[0;36mVISUAL_BERT.forward\u001b[0;34m(self, input_ids, attn_masks, token_type_ids, images)\u001b[0m\n\u001b[1;32m     17\u001b[0m visual_token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(visual_embeddings\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m visual_attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(visual_embeddings\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisual_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisual_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisual_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisual_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisual_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisual_token_type_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :])\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/.conda/envs/AICS/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/AICS/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/AICS/lib/python3.9/site-packages/transformers/models/visual_bert/modeling_visual_bert.py:788\u001b[0m, in \u001b[0;36mVisualBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, visual_embeds, visual_attention_mask, visual_token_type_ids, image_text_alignment, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;66;03m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visual_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 788\u001b[0m     combined_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisual_attention_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m     extended_attention_mask: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_extended_attention_mask(\n\u001b[1;32m    790\u001b[0m         combined_attention_mask, (batch_size, input_shape \u001b[38;5;241m+\u001b[39m visual_input_shape)\n\u001b[1;32m    791\u001b[0m     )\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 4 but got size 12 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "language_and_vision_model = VISUAL_BERT().to(device)\n",
    "\n",
    "language_and_vision_model.eval()\n",
    "total_loss = 0\n",
    "predictions = []\n",
    "gold_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        print(input_ids.size())\n",
    "        attn_masks = batch['attn_mask'].to(device)\n",
    "        token_type_ids = torch.mean(batch['token_type_ids'].float(), dim=1).to(device)\n",
    "        token_type_ids = token_type_ids.long()\n",
    "        print(token_type_ids.size())\n",
    "        images = [torch.mean(img, 0).to(device) for img in batch['imgs']]\n",
    "        #print(len(batch['imgs']))\n",
    "        gold_label = batch['rating'].to(device)\n",
    "        #print(gold_label.size())\n",
    "        outputs = language_and_vision_model(input_ids, attn_masks, token_type_ids, images)\n",
    "\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        gold_labels.extend(gold_label.cpu().numpy())\n",
    "\n",
    "        loss = loss_fn(outputs, gold_label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "average_loss = total_loss / len(dataloader)\n",
    "print(f'Average Loss: {average_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(gold_labels, predictions, squared=False)\n",
    "mae = mean_absolute_error(gold_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE: {rmse.item():.4f}\")\n",
    "print(f\"MAE: {mae.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AICS",
   "language": "python",
   "name": "aics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
